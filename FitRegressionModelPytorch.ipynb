{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSI 5238 Homework Exercise 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from sklearn import preprocessing\n",
    "torch.set_default_tensor_type('torch.DoubleTensor')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate input and output\n",
    "Generate random input x between 0 and 1 exclusively, and generate out using function f(x)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussianRan(sigma, mu=0):\n",
    "    # standard normal distribution of mean 0 variance 1\n",
    "    # For random samples from N(\\mu, \\sigma^2), use\n",
    "    return sigma*np.random.randn() + mu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test gaussian random distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n, sigma = 100, 0.1\n",
    "x = np.array([gaussianRan(sigma) for x in range(n)])\n",
    "\n",
    "bins = int(n/5)\n",
    "plt.hist(x, bins)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def functionx(x, sigma):\n",
    "    return np.cos(2*np.pi*x) + gaussianRan(sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test functionx\n",
    "n, sigma = 50, 1\n",
    "x = np.random.uniform(low=0, high=1, size=(n,1))\n",
    "y = functionx(x, sigma)\n",
    "\n",
    "bins = int(n/5)\n",
    "plt.hist(y, bins)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData(n, sigma, is_numpy=False, preprocess=False):\n",
    "    x = np.random.uniform(low=0, high=1, size=(n,1))\n",
    "    y = functionx(x, sigma)\n",
    "    \n",
    "    if preprocess:\n",
    "        x = preprocessing.scale(x)\n",
    "        y = preprocessing.scale(y)\n",
    "    \n",
    "    if is_numpy:\n",
    "        return x, y\n",
    "    return Variable(torch.from_numpy(x)), Variable(torch.from_numpy(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph input and output results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = 50\n",
    "sigma = 0.01\n",
    "x, y = getData(n, sigma, is_numpy=True, preprocess=False)\n",
    "\n",
    "plt.scatter(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define loss function, polynomial feature function, linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forwardTorchNumpy(x, y, w, lambd, is_numpy=False):\n",
    "    if is_numpy:\n",
    "        y_pred = np.dot(x,w)\n",
    "    else:\n",
    "        y_pred = torch.mm(x,w)\n",
    "    return getMSE(y_pred, y, w, lambd, is_numpy=is_numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMSE(y_pred, y, w, lambd, is_numpy=False):\n",
    "    if is_numpy:\n",
    "        return np.mean((y_pred - y)**2) + lambd*np.mean(np.dot(w.T, w))\n",
    "    return torch.mean((y_pred - y)**2) + lambd*torch.mean(torch.mm(w.t(), w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.6250)\n"
     ]
    }
   ],
   "source": [
    "# Test getMSE\n",
    "y_pred = torch.Tensor([[1.5],[1]])\n",
    "y = torch.Tensor([[2],[2]])\n",
    "w = torch.Tensor([[1],[1]])\n",
    "lambd = 1\n",
    "print(getMSE(y_pred, y, w, lambd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polynomialx(x, d, is_numpy=False):\n",
    "    if d == 0:\n",
    "        x = np.zeros_like(x)\n",
    "    else:\n",
    "        poly = preprocessing.PolynomialFeatures(d, include_bias=False)\n",
    "        x = poly.fit_transform(x)\n",
    "        \n",
    "    if is_numpy is False:\n",
    "        x = torch.from_numpy(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0],\n",
      "        [0],\n",
      "        [0]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "# Test polynomialx\n",
    "x = np.array([[2], [3], [4]])\n",
    "d = 0\n",
    "print(polynomialx(x,d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LrModule(nn.Module):\n",
    "\n",
    "    def __init__(self, d):\n",
    "        super(LrModule, self).__init__()\n",
    "        if d == 0: d = 1\n",
    "        self.linear = nn.Linear(d,1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # linear\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=1, out_features=1, bias=True)\n"
     ]
    }
   ],
   "source": [
    "# Check LrModule\n",
    "lr = LrModule(0)\n",
    "print(lr.linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test getMSE\n",
    "x = np.array([[1,2], [1,3], [1,4], [1,5]])\n",
    "y = np.array([[7], [6], [5], [4]])\n",
    "w = np.array([[0.1], [0.2]])\n",
    "y_pred = np.dot(x,w)\n",
    "res = getMSE(y_pred, y, w, lambd=0, is_numpy=True)\n",
    "assert res == 23.89"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradApprox(lr, x, y, lambd, e=1e-2):\n",
    "    w = lr.linear.weight.data\n",
    "    w = w.detach().numpy()\n",
    "    y = y.detach().numpy()\n",
    "    dwa = np.zeros_like(w)\n",
    "    \n",
    "    i = 0\n",
    "    for val in w[0]:\n",
    "        wp, wm = w.copy(), w.copy()\n",
    "\n",
    "        wp[0][i] += e\n",
    "        wm[0][i] -= e\n",
    "        \n",
    "        lr.linear.weight.data = torch.from_numpy(wp)\n",
    "        y_pred = lr.forward(x)\n",
    "        y_pred = y_pred.detach().numpy()\n",
    "        jp = getMSE(y_pred, y, wp, lambd, is_numpy=True)\n",
    "        \n",
    "        lr.linear.weight.data = torch.from_numpy(wm)\n",
    "        y_pred = lr.forward(x)\n",
    "        y_pred = y_pred.detach().numpy()\n",
    "        jm = getMSE(y_pred, y, wm, lambd, is_numpy=True)\n",
    "\n",
    "        dwa[0][i] = (jp - jm)/(2*e)\n",
    "        i += 1\n",
    "    \n",
    "    return dwa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkGrad(lr, x, y, lambd):\n",
    "    dw = lr.linear.weight.grad\n",
    "    dw = dw.detach().numpy()\n",
    "    dwa = gradApprox(lr, x, y, lambd)\n",
    "    print(\"*****************************************\")\n",
    "    print(\"dw: \", dw)\n",
    "    print(\"dwa:\", dwa)\n",
    "    e = np.linalg.norm(dw-dwa)/(np.linalg.norm(dw) + np.linalg.norm(dwa))\n",
    "    print(\"Grad approx error: \", e)\n",
    "    print(\"*****************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w:  tensor([[0.2000, 0.3000, 0.4000]])\n",
      "b:  tensor([[0.2000, 0.3000, 0.4000]])\n",
      "Cost:  tensor(2.7067, grad_fn=<ThAddBackward>)\n",
      "dw:  tensor([[-17.4667,  -8.6667, -15.8667]])\n",
      "db:  tensor([-2.8000])\n",
      "*****************************************\n",
      "dw:  [[-17.46666667  -8.66666667 -15.86666667]]\n",
      "dwa: [[-17.46666667  -8.66666667 -15.86666667]]\n",
      "Grad approx error:  2.6439547406212775e-16\n",
      "*****************************************\n"
     ]
    }
   ],
   "source": [
    "# Test LrModule gradient\n",
    "lr = LrModule(3)\n",
    "x = torch.Tensor([[8,1,6],[3,5,7],[4,9,2]])\n",
    "y = torch.Tensor([[7],[6],[5]])\n",
    "w = torch.Tensor([[0.2, 0.3, 0.4]])\n",
    "b = torch.Tensor([0.1])\n",
    "lambd = 0\n",
    "learning_rate=1e-2\n",
    "\n",
    "lr.linear.weight.data = w\n",
    "lr.linear.bias.data = b\n",
    "\n",
    "lr.linear.weight.data = w\n",
    "lr.linear.bias.data = b\n",
    "print(\"w: \", lr.linear.weight.data)\n",
    "print(\"b: \", lr.linear.weight.data)\n",
    "y_pred = lr.forward(x)\n",
    "cost = getMSE(y_pred, y, w, lambd)\n",
    "print(\"Cost: \", cost)\n",
    "cost.backward()\n",
    "dw, db = lr.linear.weight.grad, lr.linear.bias.grad\n",
    "print(\"dw: \", dw)\n",
    "print(\"db: \", db)\n",
    "\n",
    "# grad checking\n",
    "checkGrad(lr, x, y, lambd)\n",
    "\n",
    "# Update gradient\n",
    "#lr.linear.weight.data -= learning_rate*lr.linear.weight.grad.data\n",
    "#lr.linear.bias.data -= learning_rate*lr.linear.bias.grad.data\n",
    "\n",
    "# print(\"**************\")\n",
    "# print(\"w: \", lr.linear.weight.data)\n",
    "# print(\"b: \", lr.linear.weight.data)\n",
    "# lr.zero_grad()\n",
    "# y_pred = lr.forward(x)\n",
    "# cost = getMSE(y_pred, y, w, lambd)\n",
    "# print(\"Cost: \", cost)\n",
    "# cost.backward()\n",
    "# dw, db = lr.linear.weight.grad, lr.linear.bias.grad\n",
    "# print(\"dw: \", dw)\n",
    "# print(\"db: \", db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitData(x, y, d, sigma, lambd=0, learning_rate=1e-1, itera=1000, n_test=1000, check_grad=False):  \n",
    "    # create polynomial x matrix\n",
    "    x = polynomialx(x, d)\n",
    "    \n",
    "    # keep track of cost for testing\n",
    "    cost_hist = []\n",
    "    it_hist = []\n",
    "    \n",
    "    lr = LrModule(d)\n",
    "    \n",
    "    for i in range(itera):\n",
    "        # clear grads\n",
    "        lr.zero_grad()\n",
    "        \n",
    "        # Forward\n",
    "        y_pred = lr.forward(x)\n",
    "        \n",
    "        # loss\n",
    "        w = lr.linear.weight.data\n",
    "        cost = getMSE(y_pred, y, w, lambd)\n",
    "        \n",
    "        # Backward for derivative\n",
    "        cost.backward()\n",
    "        \n",
    "        # Gradient checking\n",
    "        if check_grad and i>20:\n",
    "            checkGrad(lr, x, y, lambd)\n",
    "            break\n",
    "        \n",
    "        # Update gradient\n",
    "        lr.linear.weight.data -= learning_rate*lr.linear.weight.grad.data\n",
    "        lr.linear.bias.data -= learning_rate*lr.linear.bias.grad.data\n",
    "        \n",
    "        # Save cost history for testing\n",
    "        cost_hist.append(cost.detach().numpy())\n",
    "        it_hist.append(i)\n",
    "    \n",
    "    w = lr.linear.weight.data\n",
    "    \n",
    "    # Calculate Ein\n",
    "    Ein = getMSE(lr.forward(x), y, w, lambd)\n",
    "    \n",
    "    # Create test dataset\n",
    "    x_test, y_test = getData(n_test, sigma)\n",
    "    \n",
    "    # Create x_test dimension d\n",
    "    x_test = polynomialx(x_test, d)\n",
    "    \n",
    "    # Calculate Eout\n",
    "    Eout = getMSE(lr.forward(x_test), y_test, w, lambd)\n",
    "    \n",
    "    return Ein.detach().numpy(), Eout.detach().numpy(), lr, [it_hist, cost_hist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([0.5712], requires_grad=True)\n",
      "[[-0.44799223]]\n",
      "y_pred and y\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ein:  1.7837930329171135e-05\n",
      "Eout:  0.6664503736800094\n",
      "Loss function vs iterations\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAEOdJREFUeJzt3X9sXWd9x/H3t04azM+0JEzNjy5hhECGGEFWV9ZJlPHDabUllVaxRkPrtor8sw5YkadGTDC6vyATsEkZIoKNCW20oYtCVHWzUOn+mUYXR+maJsHDlB+xzVYDTSdtHk3Cd3/c43Dj2r73Ote5OY/fL8nKPc95fO/38WN9cv2cc8+JzESSVJZrel2AJKn7DHdJKpDhLkkFMtwlqUCGuyQVyHCXpAIZ7pJUIMNdkgpkuEtSgVb06oXXrFmTmzZt6tXLS1ItHTt27IeZubZVv56F+6ZNmxgZGenVy0tSLUXE99rp57KMJBXIcJekAhnuklQgw12SCmS4S1KBDHdJKpDhLkkFMtwlqUA9+xDTYhw+PsG+4VEmz06zbnU/Q4NbuWP7+l6XJUlXndqE++HjE+w9dILpcxcAmDg7zd5DJwAMeEmapTbLMvuGRy8G+4zpcxfYNzzao4ok6epVm3CfPDvdUbskLWe1Cfd1q/s7apek5aw24T40uJX+lX2XtPWv7GNocGuPKpKkq1dtDqjOHDT1bBlJaq024Q6NgDfMJam12izLSJLaZ7hLUoEMd0kqUFvhHhE7ImI0IsYi4v459t8YEY9HxPGIeCoibu9+qZKkdrUM94joA/YDtwHbgN0RsW1Wtz8BDmbmduAu4K+6XagkqX3tvHO/CRjLzGcy8wXgQWDXrD4JvLJ6/CpgsnslSpI61U64rwfONG2PV23N/hR4X0SMA48CfzjXE0XEnogYiYiRqampRZQrSWpHO+Eec7TlrO3dwBczcwNwO/CliHjRc2fmgcwcyMyBtWvXdl6tJKkt7YT7OLCxaXsDL152uQc4CJCZ/wq8BFjTjQIlSZ1rJ9yPAlsiYnNEXEvjgOmRWX2+D7wTICLeSCPcXXeRpB5pGe6ZeR64FxgGTtM4K+ZkRDwQETurbh8G3h8R/w58GfjdzJy9dCNJukLaurZMZj5K40Bpc9tHmx6fAm7pbmmSpMXyE6qSVCDDXZIKZLhLUoEMd0kqkOEuSQUy3CWpQIa7JBXIcJekAhnuklQgw12SCmS4S1KBDHdJKpDhLkkFMtwlqUCGuyQVyHCXpAIZ7pJUIMNdkgpkuEtSgQx3SSqQ4S5JBTLcJalAhrskFchwl6QCGe6SVCDDXZIKZLhLUoEMd0kqkOEuSQUy3CWpQIa7JBXIcJekAhnuklQgw12SCmS4S1KBDHdJKlBb4R4ROyJiNCLGIuL+efq8NyJORcTJiPj77pYpSerEilYdIqIP2A+8GxgHjkbEkcw81dRnC7AXuCUzn4uI1yxVwZKk1tp5534TMJaZz2TmC8CDwK5Zfd4P7M/M5wAy89nulilJ6kQ74b4eONO0PV61NXs98PqI+JeI+EZE7JjriSJiT0SMRMTI1NTU4iqWJLXUTrjHHG05a3sFsAW4FdgNfD4iVr/omzIPZOZAZg6sXbu201olSW1qJ9zHgY1N2xuAyTn6fDUzz2Xmd4BRGmEvSeqBdsL9KLAlIjZHxLXAXcCRWX0OA+8AiIg1NJZpnulmoZKk9rUM98w8D9wLDAOngYOZeTIiHoiInVW3YeBHEXEKeBwYyswfLVXRkqSFRebs5fMrY2BgIEdGRnry2pJUVxFxLDMHWvXzE6qSVCDDXZIKZLhLUoEMd0kqkOEuSQUy3CWpQC2vCnm1OXx8gn3Do0yenWbd6n6GBrdyx/bZl7qRpOWtVuF++PgEew+dYPrcBQAmzk6z99AJAANekprUallm3/DoxWCfMX3uAvuGR3tUkSRdnWoV7pNnpztql6Tlqlbhvm51f0ftkrRc1Srchwa30r+y75K2/pV9DA1u7VFFknR1qtUB1ZmDpp4tI0kLq1W4QyPgDXNJWlitlmUkSe0x3CWpQIa7JBXIcJekAhnuklQgw12SCmS4S1KBDHdJKpDhLkkFMtwlqUCGuyQVyHCXpAIZ7pJUIMNdkgpkuEtSgQx3SSqQ4S5JBTLcJalAhrskFchwl6QCGe6SVCDDXZIK1Fa4R8SOiBiNiLGIuH+BfndGREbEQPdKlCR1qmW4R0QfsB+4DdgG7I6IbXP0ewXwAeCJbhcpSepMO+/cbwLGMvOZzHwBeBDYNUe/PwM+CfxfF+uTJC1CO+G+HjjTtD1etV0UEduBjZn5SBdrkyQtUjvhHnO05cWdEdcAnwY+3PKJIvZExEhEjExNTbVfpSSpI+2E+ziwsWl7AzDZtP0K4E3AP0fEd4GbgSNzHVTNzAOZOZCZA2vXrl181ZKkBbUT7keBLRGxOSKuBe4CjszszMznM3NNZm7KzE3AN4CdmTmyJBVLklpqGe6ZeR64FxgGTgMHM/NkRDwQETuXukBJUudWtNMpMx8FHp3V9tF5+t56+WVJki6Hn1CVpAIZ7pJUIMNdkgpkuEtSgQx3SSqQ4S5JBWrrVMiryeHjE+wbHmXy7DTrVvczNLiVO7avb/2NkrSM1CrcDx+fYO+hE0yfuwDAxNlp9h46AWDAS1KTWi3L7BsevRjsM6bPXWDf8GiPKpKkq1Otwn3y7HRH7ZK0XNUq3Net7u+oXZKWq1qF+9DgVvpX9l3S1r+yj6HBrT2qSJKuTrU6oDpz0NSzZSRpYbUKd2gEvGEuSQur1bKMJKk9hrskFchwl6QCGe6SVCDDXZIKZLhLUoEMd0kqkOEuSQUy3CWpQIa7JBXIcJekAhnuklQgw12SCmS4S1KBDHdJKpDhLkkFMtwlqUCGuyQVyHCXpAIZ7pJUoNrdIPvw8Qn2DY8yeXaadav7GRrc6g2zJWmWWoX74eMT7D10gulzFwCYODvN3kMnAAx4SWrS1rJMROyIiNGIGIuI++fYf19EnIqIpyLisYj4+e6XCvuGRy8G+4zpcxfYNzy6FC8nSbXVMtwjog/YD9wGbAN2R8S2Wd2OAwOZ+WbgYeCT3S4UYPLsdEftkrRctfPO/SZgLDOfycwXgAeBXc0dMvPxzPzfavMbwIbultmwbnV/R+2StFy1E+7rgTNN2+NV23zuAf7xcoqaz9DgVvpX9l3S1r+yj6HBrUvxcpJUW+0cUI052nLOjhHvAwaAt8+zfw+wB+DGG29ss8SfmTlo6tkykrSwdsJ9HNjYtL0BmJzdKSLeBXwEeHtm/mSuJ8rMA8ABgIGBgTn/g2jlju3rDXNJaqGdZZmjwJaI2BwR1wJ3AUeaO0TEduBzwM7MfLb7ZUqSOtEy3DPzPHAvMAycBg5m5smIeCAidlbd9gEvB74SEU9GxJF5nk6SdAW09SGmzHwUeHRW20ebHr+ry3VJki6D15aRpAIZ7pJUIMNdkgpkuEtSgQx3SSqQ4S5JBarV9dxneMMOSVpY7cLdG3ZIUmu1W5bxhh2S1Frtwt0bdkhSa7ULd2/YIUmt1S7cvWGHJLVWuwOq3rBDklqrXbiDN+yQpFZqtywjSWrNcJekAhnuklQgw12SClTLA6peW0aSFla7cPfaMpLUWu2WZby2jCS1Vrtw99oyktRa7cLda8tIUmu1C3evLSNJrdXugKrXlpGk1mr3zl2S1Frt3rl7KqQktVa7d+6eCilJrdUu3D0VUpJaq124eyqkJLVWu3B/xxvWdtQuSctR7cL98W9OddQuSctR7cJ9vrX1CdfcJemi2oX7fGvrQeM0SUlSDcN9aHArMUd7gqdDSlKlduF+x/b15Dz7XJqRpIa2wj0idkTEaESMRcT9c+xfFREPVfufiIhN3S70ktdbYJ9LM5LUxuUHIqIP2A+8GxgHjkbEkcw81dTtHuC5zHxdRNwFfAL4raUoGJj3nTvAhx56kg899ORSvbQkdcWqFdfwid9885JdNqWdd+43AWOZ+UxmvgA8COya1WcX8LfV44eBd0bEQm+wJWlZ+8n5n3LfwSeXbLWhnXBfD5xp2h6v2ubsk5nngeeBV3ejwLlc99KVS/XUknTF/DSX7kSQdsJ9vpNTOu1DROyJiJGIGJmaWvyHjj72G7+46O+VpKvJUl0Xq51wHwc2Nm1vACbn6xMRK4BXAT+e/USZeSAzBzJzYO3axV8u4I7t69nympct+vsl6WqxVNfFaifcjwJbImJzRFwL3AUcmdXnCHB39fhO4OuZudBxz8v2tftu5ZWr+lp3lKSr1DXBkt0itGW4V2vo9wLDwGngYGaejIgHImJn1e0LwKsjYgy4D3jR6ZJL4amP7+CWX7j+SryUJHXVqhXX8Kn3vmXJzpaJJX6DPa+BgYEcGRnpyWtLUl1FxLHMHGjVr3afUJUktWa4S1KBDHdJKpDhLkkFMtwlqUCGuyQVyHCXpAIZ7pJUoJ59iCkipoDvLfLb1wA/7GI5deCYlwfHvDxczph/PjNbXpyrZ+F+OSJipJ1PaJXEMS8Pjnl5uBJjdllGkgpkuEtSgeoa7gd6XUAPOOblwTEvD0s+5lquuUuSFlbXd+6SpAXULtwjYkdEjEbEWERckZuCXAkRsTEiHo+I0xFxMiI+WLVfHxFfi4hvVf9eV7VHRPxl9XN4KiLe2tsRLE5E9EXE8Yh4pNreHBFPVON9qLr7FxGxqtoeq/Zv6mXdixURqyPi4Yj4ZjXXb1sGc/xH1e/00xHx5Yh4SYnzHBF/HRHPRsTTTW0dz21E3F31/1ZE3D3Xa7WjVuEeEX3AfuA2YBuwOyK29baqrjkPfDgz3wjcDPxBNbb7gccycwvwGD+7y9VtwJbqaw/w2Stfcld8kMYdvmZ8Avh0Nd7ngHuq9nuA5zLzdcCnq3519BfAP2XmG4BfojH2Yuc4ItYDHwAGMvNNQB+NW3WWOM9fBHbMautobiPieuBjwC8DNwEfm/kPoWOZWZsv4G3AcNP2XmBvr+taorF+FXg3MArcULXdAIxWjz8H7G7qf7FfXb5o3Gz9MeDXgEeAoPHBjhWz55vGbR7fVj1eUfWLXo+hw/G+EvjO7LoLn+P1wBng+mreHgEGS51nYBPw9GLnFtgNfK6p/ZJ+nXzV6p07P/tFmTFetRWl+lN0O/AE8HOZ+QOA6t/XVN1K+Fl8Bvhj4KfV9quBs9m4by9cOqaL4632P1/1r5PXAlPA31RLUZ+PiJdR8Bxn5gTw58D3gR/QmLdjlD3PzTqd267Ned3CPeZoK+p0n4h4OfAPwIcy878X6jpHW21+FhHx68CzmXmsuXmOrtnGvrpYAbwV+Gxmbgf+h4VvJl/7MVdLCruAzcA64GU0liRmK2me2zHfOLs2/rqF+ziwsWl7AzDZo1q6LiJW0gj2v8vMQ1Xzf0XEDdX+G4Bnq/a6/yxuAXZGxHeBB2kszXwGWB0RK6o+zWO6ON5q/6uAH1/JgrtgHBjPzCeq7YdphH2pcwzwLuA7mTmVmeeAQ8CvUPY8N+t0brs253UL96PAlupI+7U0Dswc6XFNXRERAXwBOJ2Zn2radQSYOWJ+N421+Jn236mOut8MPD/z518dZObezNyQmZtozOPXM/O3gceBO6tus8c783O4s+pfq3d0mfmfwJmI2Fo1vRM4RaFzXPk+cHNEvLT6HZ8Zc7HzPEunczsMvCcirqv+6nlP1da5Xh+AWMQBi9uB/wC+DXyk1/V0cVy/SuPPr6eAJ6uv22msNz4GfKv69/qqf9A4c+jbwAkaZyP0fByLHPutwCPV49cC/waMAV8BVlXtL6m2x6r9r+113Ysc61uAkWqeDwPXlT7HwMeBbwJPA18CVpU4z8CXaRxXOEfjHfg9i5lb4Per8Y8Bv7fYevyEqiQVqG7LMpKkNhjuklQgw12SCmS4S1KBDHdJKpDhLkkFMtwlqUCGuyQV6P8BFp8RlW5nPlUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test fitData \n",
    "d, sigma, n, lambd = 1, 0.01, 2, 0\n",
    "x, y = getData(n,sigma)\n",
    "Ein, Eout, lr, plot_data = fitData(x, y, d, sigma, lambd=lambd, check_grad=False)\n",
    "\n",
    "x_poly = polynomialx(x, d)\n",
    "y_pred = lr.forward(x_poly)\n",
    "print(lr.linear.bias)\n",
    "print(lr.linear.weight.data.detach().numpy().reshape(-1,1))\n",
    "\n",
    "print(\"y_pred and y\")\n",
    "plt.scatter(x.detach().numpy(), y.detach().numpy())\n",
    "plt.scatter(x.detach().numpy(), y_pred.detach().numpy())\n",
    "plt.show()\n",
    "\n",
    "print(\"Ein: \", Ein)\n",
    "print(\"Eout: \", Eout)\n",
    "\n",
    "xx, yy = plot_data\n",
    "#print(xx)\n",
    "#print(yy)\n",
    "print(\"Loss function vs iterations\")\n",
    "plt.scatter(xx, yy)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment(n, d, sigma, lambd, trials=20, n_test=1000):\n",
    "    # initialize\n",
    "    Ein_hist, Eout_hist = np.array([]), np.array([])\n",
    "    w_hist, b_hist = np.empty([d, 0]), np.array([])\n",
    "        \n",
    "    for trail in range(trials):\n",
    "        x, y = getData(n, sigma)\n",
    "        Ein, Eout, lr, plot_data = fitData(x, y, d, sigma)\n",
    "        Ein_hist = np.append(Ein_hist, [Ein])\n",
    "        Eout_hist = np.append(Eout_hist, [Eout])\n",
    "        \n",
    "        if d == 0:\n",
    "            pass\n",
    "        else:\n",
    "            w_hist = np.append(w_hist, lr.linear.weight.data.detach().numpy().reshape(-1,1), axis=1)\n",
    "            \n",
    "        b_hist = np.append(b_hist, lr.linear.bias.data.detach().numpy().reshape(-1,1))\n",
    "    \n",
    "#     print(Ein_hist)\n",
    "#     print(Eout_hist)\n",
    "#     print(w_hist)\n",
    "#     print(b_hist)\n",
    "    \n",
    "    # take the avg\n",
    "    Ein_avg = np.mean(Ein_hist)\n",
    "    Eout_avg = np.mean(Eout_hist)\n",
    "    \n",
    "    if d == 0:\n",
    "        pass\n",
    "    else:\n",
    "        w_avg = (1/trials)*np.sum(w_hist, axis=1).reshape(1,d)\n",
    "        \n",
    "    b_avg = np.mean(b_hist)\n",
    "    \n",
    "#     print(Ein_avg)\n",
    "#     print(Eout_avg)\n",
    "#     print(w_avg)\n",
    "#     print(b_avg)\n",
    "    \n",
    "    # Create test dataset on averaged polynomials\n",
    "    x_test, y_test = getData(n_test, sigma)\n",
    "    \n",
    "    # Create x_test dimension d\n",
    "    x_test = polynomialx(x_test, d)\n",
    "    \n",
    "    # Ebias\n",
    "    if d == 0:\n",
    "        w_avg = torch.from_numpy(np.zeros((1,1)))\n",
    "    else:\n",
    "        w_avg = torch.from_numpy(w_avg)\n",
    "        \n",
    "    b_avg = torch.Tensor([b_avg])\n",
    "    lr.linear.weight.data = w_avg\n",
    "    lr.linear.bias.data = b_avg\n",
    "    Ebias = getMSE(lr.forward(x_test), y_test, w_avg, lambd)\n",
    "    Ebias = Ebias.detach().numpy()\n",
    "    Ebias = float(Ebias)\n",
    "    \n",
    "    return Ein_avg, Eout_avg, Ebias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ein_avg:  0.20804736555975611\n",
      "Eout_avg:  1.0805796385282038\n",
      "Ebias:  0.6098438194353933\n"
     ]
    }
   ],
   "source": [
    "# Test experiment \n",
    "d, sigma, n, lambd = 1, 0.01, 5, 0\n",
    "Ein_avg, Eout_avg, Ebias = experiment(n, d, sigma, lambd)\n",
    "\n",
    "print(\"Ein_avg: \", Ein_avg)\n",
    "print(\"Eout_avg: \", Eout_avg)\n",
    "print(\"Ebias: \", Ebias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize parameters for experiment\n",
    "The experiment runs through combinations of different sized input, deg of features, and sigmas for f(x). A regularization rate lamba is also set. Lambda is 0 if regularization is not used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "441\n"
     ]
    }
   ],
   "source": [
    "bigN = [2, 5, 10, 20, 50, 100, 200]\n",
    "deg = list(range(0,21))\n",
    "#deg = [19]\n",
    "sigmas = [0.01, 0.1, 1]\n",
    "#sigmas = [1]\n",
    "lambd = 0\n",
    "numCombinations = len(bigN)*len(deg)*len(sigmas)\n",
    "print(numCombinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number combinations:  441\n",
      "Experiment  1\n",
      "Inputs N, d, sigma: 2, 0, 0.01\n",
      "0.20202099866399376, 0.7013795408862928, 0.559719289726605\n",
      "Experiment  2\n",
      "Inputs N, d, sigma: 2, 0, 0.1\n",
      "0.24323448736000758, 0.8126194045945578, 0.5044950827359582\n",
      "Experiment  3\n",
      "Inputs N, d, sigma: 2, 0, 1\n",
      "0.21422772215353142, 3.70360098010457, 0.6832181373378134\n",
      "Experiment  4\n",
      "Inputs N, d, sigma: 2, 1, 0.01\n",
      "0.0009204037032872111, 1.9461148745434642, 0.6022332389563443\n",
      "Experiment  5\n",
      "Inputs N, d, sigma: 2, 1, 0.1\n",
      "0.0033297204331698615, 2.0054265632357327, 0.7952537158910008\n",
      "Experiment  6\n",
      "Inputs N, d, sigma: 2, 1, 1\n",
      "0.009048009687831673, 3.6901402499193052, 1.0113130734638134\n",
      "Experiment  7\n",
      "Inputs N, d, sigma: 2, 2, 0.01\n",
      "0.0032554254769771385, 1.6387892836286144, 0.6725325682193629\n",
      "Experiment  8\n",
      "Inputs N, d, sigma: 2, 2, 0.1\n",
      "0.0026616688166338077, 1.6775627176473418, 1.002477890829577\n",
      "Experiment  9\n",
      "Inputs N, d, sigma: 2, 2, 1\n",
      "0.002009650159076173, 3.9528690423565216, 0.5256013964064618\n",
      "Experiment  10\n",
      "Inputs N, d, sigma: 2, 3, 0.01\n",
      "0.0040339888664765585, 2.492629104756559, 0.9856796867723085\n",
      "Experiment  11\n",
      "Inputs N, d, sigma: 2, 3, 0.1\n",
      "0.0028859660573837985, 2.1789550172334815, 0.7567652466601585\n",
      "Experiment  12\n",
      "Inputs N, d, sigma: 2, 3, 1\n",
      "0.004328375363788819, 3.837511879664512, 2.7719268202251657\n",
      "Experiment  13\n",
      "Inputs N, d, sigma: 2, 4, 0.01\n",
      "0.001485020937263963, 2.38572865944911, 1.0691366238430233\n",
      "Experiment  14\n",
      "Inputs N, d, sigma: 2, 4, 0.1\n",
      "0.001257271485908999, 2.6803191922111322, 0.9860015900763562\n",
      "Experiment  15\n",
      "Inputs N, d, sigma: 2, 4, 1\n",
      "0.003582803248127175, 2.952946354396445, 0.5463404040455014\n",
      "Experiment  16\n",
      "Inputs N, d, sigma: 2, 5, 0.01\n",
      "0.003473181286965777, 1.8711508200030174, 0.7296254813826376\n",
      "Experiment  17\n",
      "Inputs N, d, sigma: 2, 5, 0.1\n",
      "0.00051283659763446, 2.2919994430166852, 0.607490849133678\n",
      "Experiment  18\n",
      "Inputs N, d, sigma: 2, 5, 1\n",
      "0.00047003364462360457, 3.755923735532671, 1.08370145304653\n",
      "Experiment  19\n",
      "Inputs N, d, sigma: 2, 6, 0.01\n",
      "0.0026130339703316747, 1.4594992608903783, 0.47112141555326825\n",
      "Experiment  20\n",
      "Inputs N, d, sigma: 2, 6, 0.1\n",
      "0.001724704974126814, 2.4861068641473176, 1.2719912396513846\n",
      "Experiment  21\n",
      "Inputs N, d, sigma: 2, 6, 1\n",
      "0.0011526486273379772, 3.2241823758205093, 5.4061416124744435\n",
      "Experiment  22\n",
      "Inputs N, d, sigma: 2, 7, 0.01\n",
      "0.001282311362081861, 1.1380592011400366, 0.4280549915533524\n",
      "Experiment  23\n",
      "Inputs N, d, sigma: 2, 7, 0.1\n",
      "0.002570910540045532, 2.185786541473134, 0.6740924715407155\n",
      "Experiment  24\n",
      "Inputs N, d, sigma: 2, 7, 1\n",
      "0.0032650503166083483, 4.160248529381788, 0.45166481974911465\n",
      "Experiment  25\n",
      "Inputs N, d, sigma: 2, 8, 0.01\n",
      "0.0044963421103610115, 2.060535661716278, 0.9417103515971207\n",
      "Experiment  26\n",
      "Inputs N, d, sigma: 2, 8, 0.1\n",
      "0.0003439778941775836, 3.1106138860475374, 1.6295509311312795\n",
      "Experiment  27\n",
      "Inputs N, d, sigma: 2, 8, 1\n",
      "0.0030764633165798016, 3.168967739708198, 0.593070477472129\n",
      "Experiment  28\n",
      "Inputs N, d, sigma: 2, 9, 0.01\n",
      "0.0012322140430134098, 2.1085618265697725, 0.8800963425516835\n",
      "Experiment  29\n",
      "Inputs N, d, sigma: 2, 9, 0.1\n",
      "0.0029921119549330636, 1.865122994950757, 0.49913211703228594\n",
      "Experiment  30\n",
      "Inputs N, d, sigma: 2, 9, 1\n",
      "0.00011829913560535523, 4.930549463180432, 8.14992249292466\n",
      "Experiment  31\n",
      "Inputs N, d, sigma: 2, 10, 0.01\n",
      "0.0028279432834297895, 3.0502124296118653, 1.4524598281156198\n",
      "Experiment  32\n",
      "Inputs N, d, sigma: 2, 10, 0.1\n",
      "0.0004471332435410188, 2.97785767353489, 1.2708345288720737\n",
      "Experiment  33\n",
      "Inputs N, d, sigma: 2, 10, 1\n",
      "0.0018686987037902214, 3.513118360170619, 0.5843560985606128\n",
      "Experiment  34\n",
      "Inputs N, d, sigma: 2, 11, 0.01\n",
      "0.0009421742112104721, 2.5366215179209037, 0.7139892072009419\n",
      "Experiment  35\n",
      "Inputs N, d, sigma: 2, 11, 0.1\n",
      "0.0010462423100789002, 1.9933615788362828, 0.6433213344803285\n",
      "Experiment  36\n",
      "Inputs N, d, sigma: 2, 11, 1\n",
      "0.0020444000385042927, 4.2220458460839065, 0.4159404483688329\n",
      "Experiment  37\n",
      "Inputs N, d, sigma: 2, 12, 0.01\n",
      "0.0008404941514557534, 2.131264820181495, 0.998623143635698\n",
      "Experiment  38\n",
      "Inputs N, d, sigma: 2, 12, 0.1\n",
      "0.0008228574256336808, 1.5703089951737925, 0.6520180133341396\n",
      "Experiment  39\n",
      "Inputs N, d, sigma: 2, 12, 1\n",
      "0.0003475852094214077, 4.063322411585561, 2.3876253363825026\n",
      "Experiment  40\n",
      "Inputs N, d, sigma: 2, 13, 0.01\n",
      "0.0021756268100843732, 2.0983519484286868, 0.751652114717935\n",
      "Experiment  41\n",
      "Inputs N, d, sigma: 2, 13, 0.1\n",
      "0.001567413772760667, 2.907745284177713, 1.1887185868319532\n",
      "Experiment  42\n",
      "Inputs N, d, sigma: 2, 13, 1\n",
      "0.0023908022835068656, 3.3690719481816975, 0.5929457423008859\n",
      "Experiment  43\n",
      "Inputs N, d, sigma: 2, 14, 0.01\n",
      "0.0027975375979819705, 1.5374336799385797, 0.4930765460967126\n",
      "Experiment  44\n",
      "Inputs N, d, sigma: 2, 14, 0.1\n",
      "0.0017662426903358483, 2.9871339515292084, 1.2455845844982314\n",
      "Experiment  45\n",
      "Inputs N, d, sigma: 2, 14, 1\n",
      "4.640004717322575e+86, 6.401245677583497e+85, 3.82676059525699e+84\n",
      "Experiment  46\n",
      "Inputs N, d, sigma: 2, 15, 0.01\n",
      "0.0009978040250554479, 3.327321666792961, 1.7703171858515931\n",
      "Experiment  47\n",
      "Inputs N, d, sigma: 2, 15, 0.1\n",
      "0.001232145570391217, 1.9095795884756275, 0.7819246329018226\n",
      "Experiment  48\n",
      "Inputs N, d, sigma: 2, 15, 1\n",
      "0.001840818931906989, 1.978360305655496, 5.182017709314113\n",
      "Experiment  49\n",
      "Inputs N, d, sigma: 2, 16, 0.01\n",
      "0.0025802166999612424, 1.8094642934290774, 0.5732625126056403\n",
      "Experiment  50\n",
      "Inputs N, d, sigma: 2, 16, 0.1\n",
      "9.153685162088234e+199, 1.1716448592692766e+199, 5.646439966016058e+197\n",
      "Experiment  51\n",
      "Inputs N, d, sigma: 2, 16, 1\n",
      "0.00066107740434829, 3.4950335923934004, 0.8644301571713653\n",
      "Experiment  52\n",
      "Inputs N, d, sigma: 2, 17, 0.01\n",
      "0.004344882479197053, 2.232965512202561, 0.5748680325622911\n",
      "Experiment  53\n",
      "Inputs N, d, sigma: 2, 17, 0.1\n",
      "0.001459012689298022, 2.4528111432061785, 0.7854658269522974\n",
      "Experiment  54\n",
      "Inputs N, d, sigma: 2, 17, 1\n",
      "0.0021171764658033856, 2.8504551371928626, 1.092439576109552\n",
      "Experiment  55\n",
      "Inputs N, d, sigma: 2, 18, 0.01\n",
      "0.0013341415865850243, 2.4090654038519945, 0.6814423216636755\n",
      "Experiment  56\n",
      "Inputs N, d, sigma: 2, 18, 0.1\n",
      "0.0010043339350386507, 1.7349745385370376, 0.6280108039357091\n",
      "Experiment  57\n",
      "Inputs N, d, sigma: 2, 18, 1\n",
      "0.001032210232285094, 2.5208802469784053, 0.6135224083966259\n",
      "Experiment  58\n",
      "Inputs N, d, sigma: 2, 19, 0.01\n",
      "0.0002654841749584533, 2.3575083002773765, 0.809084692473108\n",
      "Experiment  59\n",
      "Inputs N, d, sigma: 2, 19, 0.1\n",
      "0.0030604421314886286, 2.6726138999611493, 1.1956174869835052\n",
      "Experiment  60\n",
      "Inputs N, d, sigma: 2, 19, 1\n",
      "0.0008885681186125968, 5.695846285514913, 0.49042956064282817\n",
      "Experiment  61\n",
      "Inputs N, d, sigma: 2, 20, 0.01\n",
      "0.0018421965502699467, 1.865053735692215, 0.5143001901596522\n",
      "Experiment  62\n",
      "Inputs N, d, sigma: 2, 20, 0.1\n",
      "0.0019085758648138564, 1.7045377154469912, 0.5300594343528562\n",
      "Experiment  63\n",
      "Inputs N, d, sigma: 2, 20, 1\n",
      "9.038283222383585e+107, 1.3625543466332236e+107, 6.289607824110177e+105\n",
      "Experiment  64\n",
      "Inputs N, d, sigma: 5, 0, 0.01\n",
      "0.38942767352069985, 0.6153112408914868, 0.5004726661812472\n",
      "Experiment  65\n",
      "Inputs N, d, sigma: 5, 0, 0.1\n",
      "0.46733218623837364, 0.6350207023959034, 0.4955562239699213\n",
      "Experiment  66\n",
      "Inputs N, d, sigma: 5, 0, 1\n",
      "0.387411453582312, 1.7184473635050168, 0.5274985313361915\n",
      "Experiment  67\n",
      "Inputs N, d, sigma: 5, 1, 0.01\n",
      "0.2596278713468334, 1.4351541855584062, 0.6179886915838313\n",
      "Experiment  68\n",
      "Inputs N, d, sigma: 5, 1, 0.1\n",
      "0.20901112610678613, 1.2972433685563, 0.68669981685371\n",
      "Experiment  69\n",
      "Inputs N, d, sigma: 5, 1, 1\n",
      "0.20256977425783967, 3.532721367808312, 2.5566890132088003\n",
      "Experiment  70\n",
      "Inputs N, d, sigma: 5, 2, 0.01\n",
      "0.10728896570328321, 1.4197542442230042, 0.5950242575096568\n",
      "Experiment  71\n",
      "Inputs N, d, sigma: 5, 2, 0.1\n",
      "0.11695785606291298, 0.9017381636719877, 0.3717774436979192\n",
      "Experiment  72\n",
      "Inputs N, d, sigma: 5, 2, 1\n",
      "0.09434622188547045, 2.745378959709405, 0.6121303575602488\n",
      "Experiment  73\n",
      "Inputs N, d, sigma: 5, 3, 0.01\n",
      "0.05209772207617406, 1.1701890570542166, 0.28534837958959114\n",
      "Experiment  74\n",
      "Inputs N, d, sigma: 5, 3, 0.1\n",
      "0.05596595802924313, 0.662042353684195, 0.2729473596329594\n",
      "Experiment  75\n",
      "Inputs N, d, sigma: 5, 3, 1\n",
      "0.060948086323833604, 2.315672150867352, 1.4000505941288703\n",
      "Experiment  76\n",
      "Inputs N, d, sigma: 5, 4, 0.01\n",
      "0.04924650737362744, 0.5324377558619767, 0.11467887593153554\n",
      "Experiment  77\n",
      "Inputs N, d, sigma: 5, 4, 0.1\n",
      "0.05387907880128821, 0.44699554364203004, 0.1296306990537076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment  78\n",
      "Inputs N, d, sigma: 5, 4, 1\n",
      "0.04222917330710011, 3.529049553675784, 1.7658198864994612\n",
      "Experiment  79\n",
      "Inputs N, d, sigma: 5, 5, 0.01\n",
      "0.030294224208769694, 0.7567311806612598, 0.1880618934521185\n",
      "Experiment  80\n",
      "Inputs N, d, sigma: 5, 5, 0.1\n",
      "0.033648778274263866, 1.0886771267930053, 0.19672999226783155\n",
      "Experiment  81\n",
      "Inputs N, d, sigma: 5, 5, 1\n",
      "0.0322391229330383, 2.406320279500849, 1.470455129261775\n",
      "Experiment  82\n",
      "Inputs N, d, sigma: 5, 6, 0.01\n",
      "0.03028454413376831, 0.9331080869779264, 0.22657478863197125\n",
      "Experiment  83\n",
      "Inputs N, d, sigma: 5, 6, 0.1\n",
      "0.039336006252903816, 0.8522522297434388, 0.15042615514956964\n",
      "Experiment  84\n",
      "Inputs N, d, sigma: 5, 6, 1\n",
      "0.043780316196358526, 2.0832664630283046, 1.9166174903424358\n",
      "Experiment  85\n",
      "Inputs N, d, sigma: 5, 7, 0.01\n",
      "0.034611490941213505, 0.7855831445407169, 0.19560826232988898\n",
      "Experiment  86\n",
      "Inputs N, d, sigma: 5, 7, 0.1\n",
      "0.04137407799407942, 1.046669520282326, 0.1464496283485626\n",
      "Experiment  87\n",
      "Inputs N, d, sigma: 5, 7, 1\n",
      "0.025395439504885004, 2.092592668171375, 0.17031395286489848\n",
      "Experiment  88\n",
      "Inputs N, d, sigma: 5, 8, 0.01\n",
      "0.02053518944386786, 0.7729714188809037, 0.1891593567976354\n",
      "Experiment  89\n",
      "Inputs N, d, sigma: 5, 8, 0.1\n",
      "0.04818435149023502, 0.5442265812041592, 0.1522946710648668\n",
      "Experiment  90\n",
      "Inputs N, d, sigma: 5, 8, 1\n",
      "0.027338088321558197, 3.428571677988953, 2.4744109936538763\n",
      "Experiment  91\n",
      "Inputs N, d, sigma: 5, 9, 0.01\n",
      "0.026591464901561057, 0.5384936977737487, 0.27387788483255376\n",
      "Experiment  92\n",
      "Inputs N, d, sigma: 5, 9, 0.1\n",
      "0.041698024541842287, 0.5111676390527029, 0.23833522641671198\n",
      "Experiment  93\n",
      "Inputs N, d, sigma: 5, 9, 1\n",
      "0.037691004744427326, 2.2829139541150116, 0.6390831565036786\n",
      "Experiment  94\n",
      "Inputs N, d, sigma: 5, 10, 0.01\n",
      "0.034296314628382785, 0.5609429959822446, 0.1799905282910453\n",
      "Experiment  95\n",
      "Inputs N, d, sigma: 5, 10, 0.1\n",
      "0.03674417149119126, 0.5967524089903534, 0.3273864299426331\n",
      "Experiment  96\n",
      "Inputs N, d, sigma: 5, 10, 1\n",
      "0.03526702152505338, 3.368896717131279, 0.19646768698751227\n",
      "Experiment  97\n",
      "Inputs N, d, sigma: 5, 11, 0.01\n",
      "0.030581373088791657, 1.0555143828600024, 0.1821568587421284\n",
      "Experiment  98\n",
      "Inputs N, d, sigma: 5, 11, 0.1\n",
      "0.038959922848573816, 1.2139891047386893, 0.21786840597191134\n",
      "Experiment  99\n",
      "Inputs N, d, sigma: 5, 11, 1\n",
      "0.03272507741705006, 2.9600841068693264, 1.6712552324981604\n",
      "Experiment  100\n",
      "Inputs N, d, sigma: 5, 12, 0.01\n",
      "0.02867024654171762, 0.9177314240107061, 0.2216017301355201\n",
      "Experiment  101\n",
      "Inputs N, d, sigma: 5, 12, 0.1\n",
      "0.033478898921807124, 0.7889585545402517, 0.22392949661563458\n",
      "Experiment  102\n",
      "Inputs N, d, sigma: 5, 12, 1\n",
      "0.03393636430898565, 2.2291434038065265, 0.5815083943439893\n",
      "Experiment  103\n",
      "Inputs N, d, sigma: 5, 13, 0.01\n",
      "0.03152393757411158, 0.9895884084508282, 0.2395362668227942\n",
      "Experiment  104\n",
      "Inputs N, d, sigma: 5, 13, 0.1\n",
      "0.036304266635089205, 1.2360771039513845, 0.3772038939076595\n",
      "Experiment  105\n",
      "Inputs N, d, sigma: 5, 13, 1\n",
      "0.03320508182018138, 3.2518164076573095, 0.8014962010721769\n",
      "Experiment  106\n",
      "Inputs N, d, sigma: 5, 14, 0.01\n",
      "0.024461263755091545, 1.0955254687421436, 0.22932489417095273\n",
      "Experiment  107\n",
      "Inputs N, d, sigma: 5, 14, 0.1\n",
      "0.02980629291559051, 0.697082805487892, 0.22447344444495357\n",
      "Experiment  108\n",
      "Inputs N, d, sigma: 5, 14, 1\n",
      "0.023393636943216067, 2.0714675859690628, 0.746215246715244\n",
      "Experiment  109\n",
      "Inputs N, d, sigma: 5, 15, 0.01\n",
      "0.024925560534925114, 0.8449541442308949, 0.33031391082940853\n",
      "Experiment  110\n",
      "Inputs N, d, sigma: 5, 15, 0.1\n",
      "0.027371895644122644, 0.8654217288074484, 0.2697639335357009\n",
      "Experiment  111\n",
      "Inputs N, d, sigma: 5, 15, 1\n",
      "0.03590749105946465, 2.8294043383572314, 0.19947755494023406\n",
      "Experiment  112\n",
      "Inputs N, d, sigma: 5, 16, 0.01\n",
      "0.029914826214670592, 1.2158457582141349, 0.24986521212907697\n",
      "Experiment  113\n",
      "Inputs N, d, sigma: 5, 16, 0.1\n",
      "0.02739050172244345, 1.295474671541347, 0.25357231991353246\n",
      "Experiment  114\n",
      "Inputs N, d, sigma: 5, 16, 1\n",
      "0.042871388765137707, 4.932294193585602, 0.25122431474076234\n",
      "Experiment  115\n",
      "Inputs N, d, sigma: 5, 17, 0.01\n",
      "0.028733804776609084, 0.97955776628762, 0.3663835700710379\n",
      "Experiment  116\n",
      "Inputs N, d, sigma: 5, 17, 0.1\n",
      "0.03661385140088222, 1.168308807288367, 0.20691712807770263\n",
      "Experiment  117\n",
      "Inputs N, d, sigma: 5, 17, 1\n",
      "0.036752703707913864, 2.489779142611625, 1.268285128532875\n",
      "Experiment  118\n",
      "Inputs N, d, sigma: 5, 18, 0.01\n",
      "0.025357787011391197, 0.7319309793881363, 0.23825643324889093\n",
      "Experiment  119\n",
      "Inputs N, d, sigma: 5, 18, 0.1\n",
      "0.04089727712575203, 0.9040416831656495, 0.41373603337022574\n",
      "Experiment  120\n",
      "Inputs N, d, sigma: 5, 18, 1\n",
      "0.03214287918544616, 2.8656141413560885, 0.36823597246814976\n",
      "Experiment  121\n",
      "Inputs N, d, sigma: 5, 19, 0.01\n",
      "0.02808696345875581, 1.8308473846320878, 0.30675504364225264\n",
      "Experiment  122\n",
      "Inputs N, d, sigma: 5, 19, 0.1\n",
      "0.034147826153547736, 0.9312890666320042, 0.2607572307692073\n",
      "Experiment  123\n",
      "Inputs N, d, sigma: 5, 19, 1\n",
      "0.03335068101923566, 2.9524120098430573, 0.5156612919631789\n",
      "Experiment  124\n",
      "Inputs N, d, sigma: 5, 20, 0.01\n",
      "0.03144968850564427, 0.9790645547398269, 0.45303903441350624\n",
      "Experiment  125\n",
      "Inputs N, d, sigma: 5, 20, 0.1\n",
      "0.030497017457469196, 0.9728069911570861, 0.3097938611598321\n",
      "Experiment  126\n",
      "Inputs N, d, sigma: 5, 20, 1\n",
      "0.03698957205360176, 3.557572060172901, 0.49610927826318835\n",
      "Experiment  127\n",
      "Inputs N, d, sigma: 10, 0, 0.01\n",
      "0.41982100186468624, 0.5383114703402265, 0.5112189145316153\n",
      "Experiment  128\n",
      "Inputs N, d, sigma: 10, 0, 0.1\n",
      "0.42269316639022864, 0.5850832410018351, 0.5224037881279965\n",
      "Experiment  129\n",
      "Inputs N, d, sigma: 10, 0, 1\n",
      "0.43913582279526686, 1.8907342438555623, 1.1646387357556378\n",
      "Experiment  130\n",
      "Inputs N, d, sigma: 10, 1, 0.01\n",
      "0.42008554588161023, 0.6045294484773435, 0.509458094374498\n",
      "Experiment  131\n",
      "Inputs N, d, sigma: 10, 1, 0.1\n",
      "0.3827440111122732, 0.8982097793587828, 0.52875691290819\n",
      "Experiment  132\n",
      "Inputs N, d, sigma: 10, 1, 1\n",
      "0.35943867920657613, 3.539551938066348, 0.6937343861835112\n",
      "Experiment  133\n",
      "Inputs N, d, sigma: 10, 2, 0.01\n",
      "0.19781701594473808, 0.2537902087983581, 0.21682910309459605\n",
      "Experiment  134\n",
      "Inputs N, d, sigma: 10, 2, 0.1\n",
      "0.18949582051945205, 0.37204652971234503, 0.26615637944524645\n",
      "Experiment  135\n",
      "Inputs N, d, sigma: 10, 2, 1\n",
      "0.15323584449962685, 3.2039494631037635, 3.2860835924281413\n",
      "Experiment  136\n",
      "Inputs N, d, sigma: 10, 3, 0.01\n",
      "0.07198237319491599, 0.16341386180614187, 0.10265034682964623\n",
      "Experiment  137\n",
      "Inputs N, d, sigma: 10, 3, 0.1\n",
      "0.0776220541227273, 0.2185852692646451, 0.16425142204965454\n",
      "Experiment  138\n",
      "Inputs N, d, sigma: 10, 3, 1\n",
      "0.07220021627909194, 2.4953557066931227, 0.2859176667940306\n",
      "Experiment  139\n",
      "Inputs N, d, sigma: 10, 4, 0.01\n",
      "0.05723728270835351, 0.43719026750990553, 0.09452750580108292\n",
      "Experiment  140\n",
      "Inputs N, d, sigma: 10, 4, 0.1\n",
      "0.061820909184666706, 0.22714637418840816, 0.10892506571742093\n",
      "Experiment  141\n",
      "Inputs N, d, sigma: 10, 4, 1\n",
      "0.05922388148556958, 1.8053040289163458, 0.21332050720526005\n",
      "Experiment  142\n",
      "Inputs N, d, sigma: 10, 5, 0.01\n",
      "0.06267835650627895, 0.21844622076774897, 0.11428524275258885\n",
      "Experiment  143\n",
      "Inputs N, d, sigma: 10, 5, 0.1\n",
      "0.059992075620790085, 0.2516282989790538, 0.10504764902412828\n",
      "Experiment  144\n",
      "Inputs N, d, sigma: 10, 5, 1\n",
      "0.061294327127675206, 2.0085876204290125, 0.5640021099123403\n",
      "Experiment  145\n",
      "Inputs N, d, sigma: 10, 6, 0.01\n",
      "0.061092064908830734, 0.20719500716048503, 0.13965907393999086\n",
      "Experiment  146\n",
      "Inputs N, d, sigma: 10, 6, 0.1\n",
      "0.05765427430558032, 0.23850946359840258, 0.11985676859012713\n",
      "Experiment  147\n",
      "Inputs N, d, sigma: 10, 6, 1\n",
      "0.0726939340989986, 1.338139883503817, 0.588835626131871\n",
      "Experiment  148\n",
      "Inputs N, d, sigma: 10, 7, 0.01\n",
      "0.06777403335216536, 0.24720764435741294, 0.1257568349719873\n",
      "Experiment  149\n",
      "Inputs N, d, sigma: 10, 7, 0.1\n",
      "0.06920495605312219, 0.229663288260643, 0.1418192162427356\n",
      "Experiment  150\n",
      "Inputs N, d, sigma: 10, 7, 1\n",
      "0.06716764310045359, 1.4962209559947968, 0.36488243248681845\n",
      "Experiment  151\n",
      "Inputs N, d, sigma: 10, 8, 0.01\n",
      "0.06955680573581006, 0.2548719783675696, 0.12616697729068133\n",
      "Experiment  152\n",
      "Inputs N, d, sigma: 10, 8, 0.1\n",
      "0.0630167553757793, 0.5594407674173298, 0.14853893483487637\n",
      "Experiment  153\n",
      "Inputs N, d, sigma: 10, 8, 1\n",
      "0.06386965112362361, 1.9098535054364763, 0.3879218069279841\n",
      "Experiment  154\n",
      "Inputs N, d, sigma: 10, 9, 0.01\n",
      "0.06811125277836205, 0.3289425528594875, 0.17622356084240265\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment  155\n",
      "Inputs N, d, sigma: 10, 9, 0.1\n",
      "0.059215670189381786, 0.4579445808638707, 0.164880882699655\n",
      "Experiment  156\n",
      "Inputs N, d, sigma: 10, 9, 1\n",
      "0.05136231791564692, 2.4996009641540704, 0.2656198833856934\n",
      "Experiment  157\n",
      "Inputs N, d, sigma: 10, 10, 0.01\n",
      "0.0614298204986047, 0.32433244165538794, 0.14522288600408154\n",
      "Experiment  158\n",
      "Inputs N, d, sigma: 10, 10, 0.1\n",
      "0.05176187043362207, 0.49825212479798325, 0.22326940871035453\n",
      "Experiment  159\n",
      "Inputs N, d, sigma: 10, 10, 1\n",
      "0.06263569569321055, 1.5018604036515542, 0.8982476310193825\n",
      "Experiment  160\n",
      "Inputs N, d, sigma: 10, 11, 0.01\n",
      "0.06259048873737263, 0.27025561640254053, 0.13608660553969454\n",
      "Experiment  161\n",
      "Inputs N, d, sigma: 10, 11, 0.1\n",
      "0.045175648707763846, 0.5770773367334856, 0.2900507973799559\n",
      "Experiment  162\n",
      "Inputs N, d, sigma: 10, 11, 1\n",
      "0.0657669437307063, 2.6149581448945414, 6.243651119110752\n",
      "Experiment  163\n",
      "Inputs N, d, sigma: 10, 12, 0.01\n",
      "0.05795502178099332, 0.41333272094166507, 0.1898118941165681\n",
      "Experiment  164\n",
      "Inputs N, d, sigma: 10, 12, 0.1\n",
      "0.04735923053316602, 0.4838152214461419, 0.2198871896107447\n",
      "Experiment  165\n",
      "Inputs N, d, sigma: 10, 12, 1\n",
      "0.05143629289348293, 2.313152788308575, 0.7959068653399093\n",
      "Experiment  166\n",
      "Inputs N, d, sigma: 10, 13, 0.01\n",
      "0.04980735899747529, 0.4114388913286203, 0.1664021943556461\n",
      "Experiment  167\n",
      "Inputs N, d, sigma: 10, 13, 0.1\n",
      "0.05789163506319857, 0.43547365583927256, 0.123746005259847\n",
      "Experiment  168\n",
      "Inputs N, d, sigma: 10, 13, 1\n",
      "0.06065312056962193, 1.8555282396112645, 0.8305689306091483\n",
      "Experiment  169\n",
      "Inputs N, d, sigma: 10, 14, 0.01\n",
      "0.04821736704078923, 0.4695646057417341, 0.26522215575324865\n",
      "Experiment  170\n",
      "Inputs N, d, sigma: 10, 14, 0.1\n",
      "0.05299251969518657, 0.4802094776395706, 0.24990807884435154\n",
      "Experiment  171\n",
      "Inputs N, d, sigma: 10, 14, 1\n",
      "0.05495740054291889, 2.9218696395947408, 3.369217672677477\n",
      "Experiment  172\n",
      "Inputs N, d, sigma: 10, 15, 0.01\n",
      "0.040972422652824116, 0.4383041505819053, 0.147999783409847\n",
      "Experiment  173\n",
      "Inputs N, d, sigma: 10, 15, 0.1\n",
      "0.05120956872114799, 0.6095775206897487, 0.35088481184410575\n",
      "Experiment  174\n",
      "Inputs N, d, sigma: 10, 15, 1\n",
      "0.04932166675770176, 2.8076346416639337, 0.3139211499486522\n",
      "Experiment  175\n",
      "Inputs N, d, sigma: 10, 16, 0.01\n",
      "0.04756122207024528, 0.4650261193174132, 0.20463781298287828\n",
      "Experiment  176\n",
      "Inputs N, d, sigma: 10, 16, 0.1\n",
      "0.0490958412207307, 0.3318021435291435, 0.15475295340400377\n",
      "Experiment  177\n",
      "Inputs N, d, sigma: 10, 16, 1\n",
      "0.051976011041897696, 2.1275277386367693, 0.37238305453433745\n",
      "Experiment  178\n",
      "Inputs N, d, sigma: 10, 17, 0.01\n",
      "0.053510050315366334, 0.2218294022053251, 0.11417591594024808\n",
      "Experiment  179\n",
      "Inputs N, d, sigma: 10, 17, 0.1\n",
      "0.05330712830168101, 0.31502074673597763, 0.16127572823378633\n",
      "Experiment  180\n",
      "Inputs N, d, sigma: 10, 17, 1\n",
      "0.04588414306356878, 1.4282488951097054, 1.0556285036300521\n",
      "Experiment  181\n",
      "Inputs N, d, sigma: 10, 18, 0.01\n",
      "0.04953156934863111, 0.390183429067844, 0.14491690834784632\n",
      "Experiment  182\n",
      "Inputs N, d, sigma: 10, 18, 0.1\n",
      "0.04753849194637365, 0.31188592357678757, 0.1432909675286051\n",
      "Experiment  183\n",
      "Inputs N, d, sigma: 10, 18, 1\n",
      "0.0411389191727432, 1.5466351511994598, 4.549686080385945\n",
      "Experiment  184\n",
      "Inputs N, d, sigma: 10, 19, 0.01\n",
      "0.045066637608829604, 0.3466497200015879, 0.12167721136532512\n",
      "Experiment  185\n",
      "Inputs N, d, sigma: 10, 19, 0.1\n",
      "0.04060718329586054, 0.43051353306031237, 0.18058486404085303\n",
      "Experiment  186\n",
      "Inputs N, d, sigma: 10, 19, 1\n",
      "0.04522857578072509, 3.248238757773553, 0.5575405929134478\n",
      "Experiment  187\n",
      "Inputs N, d, sigma: 10, 20, 0.01\n",
      "0.04652983427120058, 0.4887181584185303, 0.21327253911103786\n",
      "Experiment  188\n",
      "Inputs N, d, sigma: 10, 20, 0.1\n",
      "0.04631000810380553, 0.4991582565030551, 0.15914357028665205\n",
      "Experiment  189\n",
      "Inputs N, d, sigma: 10, 20, 1\n",
      "0.04998609758097842, 2.1989028156245447, 1.1784311054468473\n",
      "Experiment  190\n",
      "Inputs N, d, sigma: 20, 0, 0.01\n",
      "0.4619596372057403, 0.5323245458889296, 0.48415796532576705\n",
      "Experiment  191\n",
      "Inputs N, d, sigma: 20, 0, 0.1\n",
      "0.47677598981437946, 0.5427800216707992, 0.5075202187412396\n",
      "Experiment  192\n",
      "Inputs N, d, sigma: 20, 0, 1\n",
      "0.47632861111919267, 1.7909665309731657, 0.7563954765936957\n",
      "Experiment  193\n",
      "Inputs N, d, sigma: 20, 1, 0.01\n",
      "0.45705634014624064, 0.5391413808147911, 0.49785475550003355\n",
      "Experiment  194\n",
      "Inputs N, d, sigma: 20, 1, 0.1\n",
      "0.46421743358099726, 0.558359603178363, 0.5044769139387015\n",
      "Experiment  195\n",
      "Inputs N, d, sigma: 20, 1, 1\n",
      "0.4590296110794256, 2.661444813131697, 0.5925938321330033\n",
      "Experiment  196\n",
      "Inputs N, d, sigma: 20, 2, 0.01\n",
      "0.18300141447990725, 0.26165432802103766, 0.22701914211187987\n",
      "Experiment  197\n",
      "Inputs N, d, sigma: 20, 2, 0.1\n",
      "0.19789082893272952, 0.2827867567749884, 0.25894230277306163\n",
      "Experiment  198\n",
      "Inputs N, d, sigma: 20, 2, 1\n",
      "0.20045299532612826, 1.2168375256546407, 0.9027097620392147\n",
      "Experiment  199\n",
      "Inputs N, d, sigma: 20, 3, 0.01\n",
      "0.07257308392280439, 0.09758387608943317, 0.0787003912676033\n",
      "Experiment  200\n",
      "Inputs N, d, sigma: 20, 3, 0.1\n",
      "0.08190091436994894, 0.13325463727230402, 0.10756368085449035\n",
      "Experiment  201\n",
      "Inputs N, d, sigma: 20, 3, 1\n",
      "0.08295793255056987, 1.9575339235467382, 2.056355606032794\n",
      "Experiment  202\n",
      "Inputs N, d, sigma: 20, 4, 0.01\n",
      "0.0679062479166098, 0.09118611758555138, 0.07641472819378665\n",
      "Experiment  203\n",
      "Inputs N, d, sigma: 20, 4, 0.1\n",
      "0.06467271657632574, 0.09701029893684866, 0.08009722468038315\n",
      "Experiment  204\n",
      "Inputs N, d, sigma: 20, 4, 1\n",
      "0.06244855539000651, 2.457077346166916, 0.492385151486695\n",
      "Experiment  205\n",
      "Inputs N, d, sigma: 20, 5, 0.01\n",
      "0.07303522349474514, 0.11276723272370588, 0.09270549809907878\n",
      "Experiment  206\n",
      "Inputs N, d, sigma: 20, 5, 0.1\n",
      "0.08194353815075948, 0.15881941770924082, 0.14000421478987196\n",
      "Experiment  207\n",
      "Inputs N, d, sigma: 20, 5, 1\n",
      "0.07757876120216163, 4.79425700821808, 5.302732771092815\n",
      "Experiment  208\n",
      "Inputs N, d, sigma: 20, 6, 0.01\n",
      "0.0764335417339743, 0.14943052115557326, 0.11234862834168753\n",
      "Experiment  209\n",
      "Inputs N, d, sigma: 20, 6, 0.1\n",
      "0.0736159154001935, 0.1771609871113246, 0.15274278366366142\n",
      "Experiment  210\n",
      "Inputs N, d, sigma: 20, 6, 1\n",
      "0.07838765297626873, 1.7340613796050668, 0.4548606212148122\n",
      "Experiment  211\n",
      "Inputs N, d, sigma: 20, 7, 0.01\n",
      "0.08169362316316903, 0.16655135461250234, 0.12174677450991943\n",
      "Experiment  212\n",
      "Inputs N, d, sigma: 20, 7, 0.1\n",
      "0.08069274723067062, 0.21087520286077663, 0.134387953041265\n",
      "Experiment  213\n",
      "Inputs N, d, sigma: 20, 7, 1\n",
      "0.08270225126073624, 1.589996606072953, 0.7576358251549298\n",
      "Experiment  214\n",
      "Inputs N, d, sigma: 20, 8, 0.01\n",
      "0.081284635413516, 0.2071542600184207, 0.1107325595530446\n",
      "Experiment  215\n",
      "Inputs N, d, sigma: 20, 8, 0.1\n",
      "0.07740063549840638, 0.22464050125493396, 0.13969885570102833\n",
      "Experiment  216\n",
      "Inputs N, d, sigma: 20, 8, 1\n",
      "0.08373420161951771, 3.112760449941816, 0.1285104745138515\n",
      "Experiment  217\n",
      "Inputs N, d, sigma: 20, 9, 0.01\n",
      "0.08088513078395432, 0.18255938556256665, 0.116629843317188\n",
      "Experiment  218\n",
      "Inputs N, d, sigma: 20, 9, 0.1\n",
      "0.07962339673266412, 0.17206284647927017, 0.10394976353615071\n",
      "Experiment  219\n",
      "Inputs N, d, sigma: 20, 9, 1\n",
      "0.07302963158949095, 1.450759398161648, 0.1690116488947041\n",
      "Experiment  220\n",
      "Inputs N, d, sigma: 20, 10, 0.01\n",
      "0.0760213157627349, 0.16873916371166392, 0.11148420441688636\n",
      "Experiment  221\n",
      "Inputs N, d, sigma: 20, 10, 0.1\n",
      "0.06937541492324853, 0.2729767566100415, 0.15556160627055493\n",
      "Experiment  222\n",
      "Inputs N, d, sigma: 20, 10, 1\n",
      "0.07402003277151775, 2.9042047135013287, 0.1565638334476625\n",
      "Experiment  223\n",
      "Inputs N, d, sigma: 20, 11, 0.01\n",
      "0.06368224355513732, 0.32896153070934664, 0.1934558313489237\n",
      "Experiment  224\n",
      "Inputs N, d, sigma: 20, 11, 0.1\n",
      "0.0694287831058703, 0.2153278637556549, 0.09978507812043937\n",
      "Experiment  225\n",
      "Inputs N, d, sigma: 20, 11, 1\n",
      "0.06782920240326254, 2.5196604079515463, 0.18364284099650524\n",
      "Experiment  226\n",
      "Inputs N, d, sigma: 20, 12, 0.01\n",
      "0.06612009863100313, 0.13590697242827848, 0.09171799032022414\n",
      "Experiment  227\n",
      "Inputs N, d, sigma: 20, 12, 0.1\n",
      "0.06548355501745126, 0.13942245875304607, 0.11048665293122963\n",
      "Experiment  228\n",
      "Inputs N, d, sigma: 20, 12, 1\n",
      "0.06632009590199883, 1.5209563449058732, 7.563255420131318\n",
      "Experiment  229\n",
      "Inputs N, d, sigma: 20, 13, 0.01\n",
      "0.06034643644428552, 0.12932216579025352, 0.07383680502569186\n",
      "Experiment  230\n",
      "Inputs N, d, sigma: 20, 13, 0.1\n",
      "0.058445348509685094, 0.2471164601389689, 0.10409313709427533\n",
      "Experiment  231\n",
      "Inputs N, d, sigma: 20, 13, 1\n",
      "0.060330650068777913, 3.3441505839996695, 4.992136509266471\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment  232\n",
      "Inputs N, d, sigma: 20, 14, 0.01\n",
      "0.052828479537687364, 0.2530482192453298, 0.10519796219929167\n",
      "Experiment  233\n",
      "Inputs N, d, sigma: 20, 14, 0.1\n",
      "0.057233370261039265, 0.16106043814936719, 0.09941525547582918\n",
      "Experiment  234\n",
      "Inputs N, d, sigma: 20, 14, 1\n",
      "0.059466062304204384, 1.9995710663683313, 3.282425173816454\n",
      "Experiment  235\n",
      "Inputs N, d, sigma: 20, 15, 0.01\n",
      "0.060125684620227424, 0.22174717607695257, 0.10808570874419286\n",
      "Experiment  236\n",
      "Inputs N, d, sigma: 20, 15, 0.1\n",
      "0.054277093163627964, 0.10570994842119448, 0.07121510004897776\n",
      "Experiment  237\n",
      "Inputs N, d, sigma: 20, 15, 1\n",
      "0.0541003288926041, 4.044453853833346, 0.11401056447467449\n",
      "Experiment  238\n",
      "Inputs N, d, sigma: 20, 16, 0.01\n",
      "0.05308009556224116, 0.25384140803058036, 0.11993631274590599\n",
      "Experiment  239\n",
      "Inputs N, d, sigma: 20, 16, 0.1\n",
      "0.053581964412845004, 0.35235082440971954, 0.11725755901802175\n",
      "Experiment  240\n",
      "Inputs N, d, sigma: 20, 16, 1\n",
      "0.04664962174371988, 2.3167643322986256, 0.1494683458839032\n",
      "Experiment  241\n",
      "Inputs N, d, sigma: 20, 17, 0.01\n",
      "0.05200271797077245, 0.10611404602004323, 0.07001514712853044\n",
      "Experiment  242\n",
      "Inputs N, d, sigma: 20, 17, 0.1\n",
      "0.052627262923893345, 0.2100032443731429, 0.12265570359378627\n",
      "Experiment  243\n",
      "Inputs N, d, sigma: 20, 17, 1\n",
      "0.05195386495967759, 2.0308482198603115, 0.42964941811511054\n",
      "Experiment  244\n",
      "Inputs N, d, sigma: 20, 18, 0.01\n",
      "0.05321974758999835, 0.1556473147972807, 0.08283997843864709\n",
      "Experiment  245\n",
      "Inputs N, d, sigma: 20, 18, 0.1\n",
      "0.05202157938006632, 0.19629579311592396, 0.08458474960754443\n",
      "Experiment  246\n",
      "Inputs N, d, sigma: 20, 18, 1\n",
      "0.05624660669261541, 3.4464691851541267, 0.4264504367206056\n",
      "Experiment  247\n",
      "Inputs N, d, sigma: 20, 19, 0.01\n",
      "0.05120324620890763, 0.35733025099103166, 0.14543222581739498\n",
      "Experiment  248\n",
      "Inputs N, d, sigma: 20, 19, 0.1\n",
      "0.05505107207082406, 0.17130598877734943, 0.07620097629695792\n",
      "Experiment  249\n",
      "Inputs N, d, sigma: 20, 19, 1\n",
      "0.052709005310771884, 1.5427173403173648, 0.10658786104127253\n",
      "Experiment  250\n",
      "Inputs N, d, sigma: 20, 20, 0.01\n",
      "0.048114068328312255, 0.21387707769168823, 0.09780857460583664\n",
      "Experiment  251\n",
      "Inputs N, d, sigma: 20, 20, 0.1\n",
      "0.048006003884071856, 0.2529271086001673, 0.08991216762396782\n",
      "Experiment  252\n",
      "Inputs N, d, sigma: 20, 20, 1\n",
      "0.049341865288874034, 4.392261000539755, 1.4028017868371176\n",
      "Experiment  253\n",
      "Inputs N, d, sigma: 50, 0, 0.01\n",
      "0.49899896718651177, 0.5045134915165255, 0.49228620792888916\n",
      "Experiment  254\n",
      "Inputs N, d, sigma: 50, 0, 0.1\n",
      "0.48563575334381415, 0.5596490846299143, 0.4811707413644001\n",
      "Experiment  255\n",
      "Inputs N, d, sigma: 50, 0, 1\n",
      "0.4758781401431909, 1.8531644400032412, 0.764790909046181\n",
      "Experiment  256\n",
      "Inputs N, d, sigma: 50, 1, 0.01\n",
      "0.4904076272057307, 0.5124101583142282, 0.5078610022895289\n",
      "Experiment  257\n",
      "Inputs N, d, sigma: 50, 1, 0.1\n",
      "0.4952636238042949, 0.5290414400258744, 0.5120698743604493\n",
      "Experiment  258\n",
      "Inputs N, d, sigma: 50, 1, 1\n",
      "0.49643110635877885, 2.7255727697074783, 0.5238180192617823\n",
      "Experiment  259\n",
      "Inputs N, d, sigma: 50, 2, 0.01\n",
      "0.19742875186048067, 0.21041287038604994, 0.19939407407919943\n",
      "Experiment  260\n",
      "Inputs N, d, sigma: 50, 2, 0.1\n",
      "0.1907060432612422, 0.23527624710371625, 0.2724574267322962\n",
      "Experiment  261\n",
      "Inputs N, d, sigma: 50, 2, 1\n",
      "0.18567627902123154, 2.2784034125928345, 3.5467984832882897\n",
      "Experiment  262\n",
      "Inputs N, d, sigma: 50, 3, 0.01\n",
      "0.07580209527068349, 0.08371584695789096, 0.08260630367612899\n",
      "Experiment  263\n",
      "Inputs N, d, sigma: 50, 3, 0.1\n",
      "0.07604057814348622, 0.09868621098385202, 0.08356620752551731\n",
      "Experiment  264\n",
      "Inputs N, d, sigma: 50, 3, 1\n",
      "0.07690438558759585, 1.3811584725459225, 2.27468582110964\n",
      "Experiment  265\n",
      "Inputs N, d, sigma: 50, 4, 0.01\n",
      "0.06916182678346541, 0.08167662983610381, 0.07581269899846102\n",
      "Experiment  266\n",
      "Inputs N, d, sigma: 50, 4, 0.1\n",
      "0.06726422855105789, 0.10839398752056609, 0.08828045268457997\n",
      "Experiment  267\n",
      "Inputs N, d, sigma: 50, 4, 1\n",
      "0.06690231475037621, 2.1747071976369563, 0.30497248028100366\n",
      "Experiment  268\n",
      "Inputs N, d, sigma: 50, 5, 0.01\n",
      "0.07767001681581659, 0.11082268645600539, 0.09325004086164876\n",
      "Experiment  269\n",
      "Inputs N, d, sigma: 50, 5, 0.1\n",
      "0.07938065753855253, 0.11942875738297294, 0.103001693730029\n",
      "Experiment  270\n",
      "Inputs N, d, sigma: 50, 5, 1\n",
      "0.08026602580487195, 1.8477101787537449, 0.09789350067809861\n",
      "Experiment  271\n",
      "Inputs N, d, sigma: 50, 6, 0.01\n",
      "0.08824961462458225, 0.11892681946613588, 0.11033290148943208\n",
      "Experiment  272\n",
      "Inputs N, d, sigma: 50, 6, 0.1\n",
      "0.09473408661861554, 0.14595253106376344, 0.1278830354269029\n",
      "Experiment  273\n",
      "Inputs N, d, sigma: 50, 6, 1\n",
      "0.09152072543274625, 2.342535776902123, 0.4771334149393504\n",
      "Experiment  274\n",
      "Inputs N, d, sigma: 50, 7, 0.01\n",
      "0.09143718458820205, 0.12398653863549267, 0.10747600791699433\n",
      "Experiment  275\n",
      "Inputs N, d, sigma: 50, 7, 0.1\n",
      "0.10093362196967533, 0.13879045400788387, 0.14034116987961254\n",
      "Experiment  276\n",
      "Inputs N, d, sigma: 50, 7, 1\n",
      "0.09694794469461375, 1.9501880837200638, 0.5417139541661422\n",
      "Experiment  277\n",
      "Inputs N, d, sigma: 50, 8, 0.01\n",
      "0.09029880666721589, 0.11711911979542203, 0.10536529687014626\n",
      "Experiment  278\n",
      "Inputs N, d, sigma: 50, 8, 0.1\n",
      "0.09060348584442814, 0.1298943518333427, 0.10159767827135202\n",
      "Experiment  279\n",
      "Inputs N, d, sigma: 50, 8, 1\n",
      "0.09204797041641506, 1.7076340341750007, 2.856278347039612\n",
      "Experiment  280\n",
      "Inputs N, d, sigma: 50, 9, 0.01\n",
      "0.08372246253015679, 0.10933010765763718, 0.09262441033321613\n",
      "Experiment  281\n",
      "Inputs N, d, sigma: 50, 9, 0.1\n",
      "0.08354034173499762, 0.1058832439019484, 0.08787688102655257\n",
      "Experiment  282\n",
      "Inputs N, d, sigma: 50, 9, 1\n",
      "0.08524859282697847, 2.340622918133915, 0.3174410124318921\n",
      "Experiment  283\n",
      "Inputs N, d, sigma: 50, 10, 0.01\n",
      "0.07753037368917061, 0.09336721111924907, 0.08194740377075083\n",
      "Experiment  284\n",
      "Inputs N, d, sigma: 50, 10, 0.1\n",
      "0.07790943180803503, 0.11827148632851388, 0.08321639074098089\n",
      "Experiment  285\n",
      "Inputs N, d, sigma: 50, 10, 1\n",
      "0.0760857305763435, 3.2734129860379553, 0.09653012599650568\n",
      "Experiment  286\n",
      "Inputs N, d, sigma: 50, 11, 0.01\n",
      "0.06985287877334909, 0.08421702934773141, 0.07696093136402274\n",
      "Experiment  287\n",
      "Inputs N, d, sigma: 50, 11, 0.1\n",
      "0.06968819733411553, 0.09862549187836536, 0.07402443850866247\n",
      "Experiment  288\n",
      "Inputs N, d, sigma: 50, 11, 1\n",
      "0.06992179833839446, 2.4935049840244825, 0.11448516461666916\n",
      "Experiment  289\n",
      "Inputs N, d, sigma: 50, 12, 0.01\n",
      "0.06562624052292518, 0.07786751547576468, 0.07304759149245703\n",
      "Experiment  290\n",
      "Inputs N, d, sigma: 50, 12, 0.1\n",
      "0.06311799307773165, 0.09260897310223415, 0.07029587013598447\n",
      "Experiment  291\n",
      "Inputs N, d, sigma: 50, 12, 1\n",
      "0.06566963055220475, 4.534241814964501, 0.6583445690999223\n",
      "Experiment  292\n",
      "Inputs N, d, sigma: 50, 13, 0.01\n",
      "0.05991404994507934, 0.07659429329445808, 0.0677595951394987\n",
      "Experiment  293\n",
      "Inputs N, d, sigma: 50, 13, 0.1\n",
      "0.05911808542212597, 0.11163621149511098, 0.10225557931818861\n",
      "Experiment  294\n",
      "Inputs N, d, sigma: 50, 13, 1\n",
      "0.05632482308617811, 2.4634897108414755, 0.6446425185715264\n",
      "Experiment  295\n",
      "Inputs N, d, sigma: 50, 14, 0.01\n",
      "0.054412445170076706, 0.059760883727061155, 0.055846117850728065\n",
      "Experiment  296\n",
      "Inputs N, d, sigma: 50, 14, 0.1\n",
      "0.05355563237027535, 0.08544914025644647, 0.07205233202913858\n",
      "Experiment  297\n",
      "Inputs N, d, sigma: 50, 14, 1\n",
      "0.05522567837139223, 1.7331471853249074, 0.6716829211029496\n",
      "Experiment  298\n",
      "Inputs N, d, sigma: 50, 15, 0.01\n",
      "0.051045332160891944, 0.07002396844603226, 0.057153008263183314\n",
      "Experiment  299\n",
      "Inputs N, d, sigma: 50, 15, 0.1\n",
      "0.05211750691031539, 0.09767586936416264, 0.06514627923338705\n",
      "Experiment  300\n",
      "Inputs N, d, sigma: 50, 15, 1\n",
      "0.051420549645516365, 2.0375955446148555, 0.36072320870613833\n",
      "Experiment  301\n",
      "Inputs N, d, sigma: 50, 16, 0.01\n",
      "0.05206852224949279, 0.07304751811192989, 0.05731342880943775\n",
      "Experiment  302\n",
      "Inputs N, d, sigma: 50, 16, 0.1\n",
      "0.05304652537980268, 0.08528374220444992, 0.06314181150051047\n",
      "Experiment  303\n",
      "Inputs N, d, sigma: 50, 16, 1\n",
      "0.04865488111115723, 2.545883230929471, 0.25512096861474004\n",
      "Experiment  304\n",
      "Inputs N, d, sigma: 50, 17, 0.01\n",
      "0.048358148778525054, 0.06071522433383382, 0.049854651430689415\n",
      "Experiment  305\n",
      "Inputs N, d, sigma: 50, 17, 0.1\n",
      "0.0487011738541696, 0.06939707831994109, 0.16996202511049205\n",
      "Experiment  306\n",
      "Inputs N, d, sigma: 50, 17, 1\n",
      "0.051824212934022874, 1.693854673763631, 0.0912528500062125\n",
      "Experiment  307\n",
      "Inputs N, d, sigma: 50, 18, 0.01\n",
      "0.048474751899391766, 0.057945067406502904, 0.05426316530927151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment  308\n",
      "Inputs N, d, sigma: 50, 18, 0.1\n",
      "0.04713411709361079, 0.07429610538711935, 0.05120576825687863\n",
      "Experiment  309\n",
      "Inputs N, d, sigma: 50, 18, 1\n",
      "0.05267200692799347, 1.6611492425612842, 0.07235110565722105\n",
      "Experiment  310\n",
      "Inputs N, d, sigma: 50, 19, 0.01\n",
      "0.05245749512425803, 0.07556353481155928, 0.05515600334993943\n",
      "Experiment  311\n",
      "Inputs N, d, sigma: 50, 19, 0.1\n",
      "0.048089921501097074, 0.0670223179981722, 0.10179722403759849\n",
      "Experiment  312\n",
      "Inputs N, d, sigma: 50, 19, 1\n",
      "0.04911199603266806, 2.021796266374524, 0.32505807514291485\n",
      "Experiment  313\n",
      "Inputs N, d, sigma: 50, 20, 0.01\n",
      "0.04992841576698477, 0.059751430431280714, 0.05327844335267754\n",
      "Experiment  314\n",
      "Inputs N, d, sigma: 50, 20, 0.1\n",
      "0.05004391612489837, 0.06826137206738411, 0.07106441014159234\n",
      "Experiment  315\n",
      "Inputs N, d, sigma: 50, 20, 1\n",
      "0.05395813117121895, 1.1297055355288506, 0.35319857276166144\n",
      "Experiment  316\n",
      "Inputs N, d, sigma: 100, 0, 0.01\n",
      "0.4927505228795181, 0.5064631773455973, 0.5045847089702751\n",
      "Experiment  317\n",
      "Inputs N, d, sigma: 100, 0, 0.1\n",
      "0.5009440983136462, 0.5171377558752555, 0.5198957061407266\n",
      "Experiment  318\n",
      "Inputs N, d, sigma: 100, 0, 1\n",
      "0.47657524000518914, 2.7579154715065117, 2.5452483931220677\n",
      "Experiment  319\n",
      "Inputs N, d, sigma: 100, 1, 0.01\n",
      "0.47041781209359124, 0.510426570168631, 0.4979689593700265\n",
      "Experiment  320\n",
      "Inputs N, d, sigma: 100, 1, 0.1\n",
      "0.48206055690949795, 0.5201737692708037, 0.5180518527330508\n",
      "Experiment  321\n",
      "Inputs N, d, sigma: 100, 1, 1\n",
      "0.49390652866515794, 2.2253654766720725, 0.6761669336381765\n",
      "Experiment  322\n",
      "Inputs N, d, sigma: 100, 2, 0.01\n",
      "0.1957245830589233, 0.20776479709989223, 0.21232948214776703\n",
      "Experiment  323\n",
      "Inputs N, d, sigma: 100, 2, 0.1\n",
      "0.19486256137775032, 0.21815496797871076, 0.20482555979927583\n",
      "Experiment  324\n",
      "Inputs N, d, sigma: 100, 2, 1\n",
      "0.19355397119827927, 2.240400852778209, 1.7144771776807042\n",
      "Experiment  325\n",
      "Inputs N, d, sigma: 100, 3, 0.01\n",
      "0.0783581041317479, 0.08158518368963512, 0.07875852040905337\n",
      "Experiment  326\n",
      "Inputs N, d, sigma: 100, 3, 0.1\n",
      "0.0756331937852903, 0.093820684310804, 0.07924859168054967\n",
      "Experiment  327\n",
      "Inputs N, d, sigma: 100, 3, 1\n",
      "0.07610057644677784, 2.9869613662782206, 0.4376710216041426\n",
      "Experiment  328\n",
      "Inputs N, d, sigma: 100, 4, 0.01\n",
      "0.07620401921014192, 0.07978404543633703, 0.07861568653683919\n",
      "Experiment  329\n",
      "Inputs N, d, sigma: 100, 4, 0.1\n",
      "0.07108385735864883, 0.09848307543106595, 0.17873346399159698\n",
      "Experiment  330\n",
      "Inputs N, d, sigma: 100, 4, 1\n",
      "0.07169216707200757, 3.4333981940713096, 0.07970035103986876\n",
      "Experiment  331\n",
      "Inputs N, d, sigma: 100, 5, 0.01\n",
      "0.08785004368585139, 0.09479364390186276, 0.09098169789819885\n",
      "Experiment  332\n",
      "Inputs N, d, sigma: 100, 5, 0.1\n",
      "0.08923517830282626, 0.11079323931279787, 0.09392046819781849\n",
      "Experiment  333\n",
      "Inputs N, d, sigma: 100, 5, 1\n",
      "0.08579712809862425, 1.545171786765227, 0.1395767333386854\n",
      "Experiment  334\n",
      "Inputs N, d, sigma: 100, 6, 0.01\n",
      "0.0954290731511406, 0.10981457127562244, 0.10404566616835835\n",
      "Experiment  335\n",
      "Inputs N, d, sigma: 100, 6, 0.1\n",
      "0.09986894529188262, 0.12145400280264833, 0.10817841251223684\n",
      "Experiment  336\n",
      "Inputs N, d, sigma: 100, 6, 1\n",
      "0.10071040098481157, 2.1154965278062403, 0.6870960747278093\n",
      "Experiment  337\n",
      "Inputs N, d, sigma: 100, 7, 0.01\n",
      "0.10282203029480882, 0.10992553360737753, 0.10306189502627246\n",
      "Experiment  338\n",
      "Inputs N, d, sigma: 100, 7, 0.1\n",
      "0.10184896922429325, 0.12105455897427882, 0.10522106285792945\n",
      "Experiment  339\n",
      "Inputs N, d, sigma: 100, 7, 1\n",
      "0.09566223930865632, 2.392836704865592, 2.40723494896789\n",
      "Experiment  340\n",
      "Inputs N, d, sigma: 100, 8, 0.01\n",
      "0.09454682404675512, 0.102874941726224, 0.09928127787458167\n",
      "Experiment  341\n",
      "Inputs N, d, sigma: 100, 8, 0.1\n",
      "0.09254960092796155, 0.11129048711713845, 0.11664865901288943\n",
      "Experiment  342\n",
      "Inputs N, d, sigma: 100, 8, 1\n",
      "0.09407207277330908, 3.011502212093748, 0.4448600399357313\n",
      "Experiment  343\n",
      "Inputs N, d, sigma: 100, 9, 0.01\n",
      "0.08630849232191061, 0.09487648571655076, 0.08988838708902244\n",
      "Experiment  344\n",
      "Inputs N, d, sigma: 100, 9, 0.1\n",
      "0.08699819419374502, 0.11483965628842337, 0.08949345493494473\n",
      "Experiment  345\n",
      "Inputs N, d, sigma: 100, 9, 1\n",
      "0.08826795626242356, 1.3228521103026172, 0.3333344618465245\n",
      "Experiment  346\n",
      "Inputs N, d, sigma: 100, 10, 0.01\n",
      "0.07706528447440075, 0.08920379457909575, 0.08464541695156816\n",
      "Experiment  347\n",
      "Inputs N, d, sigma: 100, 10, 0.1\n",
      "0.07901689670374819, 0.11504671760133264, 0.08157168811821992\n",
      "Experiment  348\n",
      "Inputs N, d, sigma: 100, 10, 1\n",
      "0.07908002983472798, 1.85467398525785, 0.12439835840073128\n",
      "Experiment  349\n",
      "Inputs N, d, sigma: 100, 11, 0.01\n",
      "0.0688249921142117, 0.07433541059781085, 0.07176421425754612\n",
      "Experiment  350\n",
      "Inputs N, d, sigma: 100, 11, 0.1\n",
      "0.0695162557286962, 0.09208995324494582, 0.07738775314804955\n",
      "Experiment  351\n",
      "Inputs N, d, sigma: 100, 11, 1\n",
      "0.06939578796586061, 1.2224228651578366, 0.3142731099219202\n",
      "Experiment  352\n",
      "Inputs N, d, sigma: 100, 12, 0.01\n",
      "0.060112930257549047, 0.06481812672507528, 0.06296553554802033\n",
      "Experiment  353\n",
      "Inputs N, d, sigma: 100, 12, 0.1\n",
      "0.06443367735341049, 0.0839844486926126, 0.06968114952821584\n",
      "Experiment  354\n",
      "Inputs N, d, sigma: 100, 12, 1\n",
      "0.06173755900361816, 1.5681714528317012, 0.06951922700258664\n",
      "Experiment  355\n",
      "Inputs N, d, sigma: 100, 13, 0.01\n",
      "0.05473385878923439, 0.058582247427127955, 0.05623175929687749\n",
      "Experiment  356\n",
      "Inputs N, d, sigma: 100, 13, 0.1\n",
      "0.055615987803842096, 0.07146033589449986, 0.05404038043349626\n",
      "Experiment  357\n",
      "Inputs N, d, sigma: 100, 13, 1\n",
      "0.054387370012446444, 1.9295025370150587, 1.142985593605071\n",
      "Experiment  358\n",
      "Inputs N, d, sigma: 100, 14, 0.01\n",
      "0.05242527074073309, 0.05744981220396983, 0.055787999066178734\n",
      "Experiment  359\n",
      "Inputs N, d, sigma: 100, 14, 0.1\n",
      "0.05298606706084572, 0.07568008735271542, 0.05849842847786462\n",
      "Experiment  360\n",
      "Inputs N, d, sigma: 100, 14, 1\n",
      "0.05066825112902089, 1.798256993402958, 0.9517155687809349\n",
      "Experiment  361\n",
      "Inputs N, d, sigma: 100, 15, 0.01\n",
      "0.049565181666098794, 0.052401550133414666, 0.050153174299018215\n",
      "Experiment  362\n",
      "Inputs N, d, sigma: 100, 15, 0.1\n",
      "0.050432097498713545, 0.06697101184196996, 0.0510696976326981\n",
      "Experiment  363\n",
      "Inputs N, d, sigma: 100, 15, 1\n",
      "0.04960850490174395, 1.673389712521026, 0.7339318444405059\n",
      "Experiment  364\n",
      "Inputs N, d, sigma: 100, 16, 0.01\n",
      "0.04960676193837325, 0.05459729236275899, 0.052223318101109015\n",
      "Experiment  365\n",
      "Inputs N, d, sigma: 100, 16, 0.1\n",
      "0.04902477152244062, 0.06674321032567271, 0.08381157218073995\n",
      "Experiment  366\n",
      "Inputs N, d, sigma: 100, 16, 1\n",
      "0.04797296923142059, 2.414429924923662, 0.8028996563293022\n",
      "Experiment  367\n",
      "Inputs N, d, sigma: 100, 17, 0.01\n",
      "0.04961806345616978, 0.05214732277674391, 0.05148726111558567\n",
      "Experiment  368\n",
      "Inputs N, d, sigma: 100, 17, 0.1\n",
      "0.048205144346627433, 0.06306258406455278, 0.05144868791847053\n",
      "Experiment  369\n",
      "Inputs N, d, sigma: 100, 17, 1\n",
      "0.04902837302941396, 1.4538092195306374, 0.0510250560482192\n",
      "Experiment  370\n",
      "Inputs N, d, sigma: 100, 18, 0.01\n",
      "0.04865376559930128, 0.052014976089751655, 0.051350975583746065\n",
      "Experiment  371\n",
      "Inputs N, d, sigma: 100, 18, 0.1\n",
      "0.04762867668198519, 0.07081406850554847, 0.05456841930286847\n",
      "Experiment  372\n",
      "Inputs N, d, sigma: 100, 18, 1\n",
      "0.04945389213780964, 1.5342130533532823, 0.5617044033701659\n",
      "Experiment  373\n",
      "Inputs N, d, sigma: 100, 19, 0.01\n",
      "0.04870068145275523, 0.053207282817667456, 0.05279656009650591\n",
      "Experiment  374\n",
      "Inputs N, d, sigma: 100, 19, 0.1\n",
      "0.04774115561927887, 0.07186250084700692, 0.06966768743807815\n",
      "Experiment  375\n",
      "Inputs N, d, sigma: 100, 19, 1\n",
      "0.04959850911281799, 1.922106692390368, 1.5603695335417254\n",
      "Experiment  376\n",
      "Inputs N, d, sigma: 100, 20, 0.01\n",
      "0.04981954273685374, 0.05393384977975111, 0.05127105875057449\n",
      "Experiment  377\n",
      "Inputs N, d, sigma: 100, 20, 0.1\n",
      "0.05001052829357307, 0.07917859228611675, 0.054117199721399216\n",
      "Experiment  378\n",
      "Inputs N, d, sigma: 100, 20, 1\n",
      "0.049421070558579805, 1.4575683006353608, 0.14340218308737934\n",
      "Experiment  379\n",
      "Inputs N, d, sigma: 200, 0, 0.01\n",
      "0.49797113889890215, 0.503035910730665, 0.4777467878117448\n",
      "Experiment  380\n",
      "Inputs N, d, sigma: 200, 0, 0.1\n",
      "0.5036815839803708, 0.513457676230314, 0.5023739323606797\n",
      "Experiment  381\n",
      "Inputs N, d, sigma: 200, 0, 1\n",
      "0.5008947017543289, 1.331811690830563, 0.6883962860121072\n",
      "Experiment  382\n",
      "Inputs N, d, sigma: 200, 1, 0.01\n",
      "0.49974089918719516, 0.5095950047020535, 0.4991722056438096\n",
      "Experiment  383\n",
      "Inputs N, d, sigma: 200, 1, 0.1\n",
      "0.4906884160152501, 0.5237212450382496, 0.5328788566923676\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment  384\n",
      "Inputs N, d, sigma: 200, 1, 1\n",
      "0.4995241410149447, 2.23942813366453, 0.785732284682528\n",
      "Experiment  385\n",
      "Inputs N, d, sigma: 200, 2, 0.01\n",
      "0.191401302076039, 0.19712466451378985, 0.19444478823028086\n",
      "Experiment  386\n",
      "Inputs N, d, sigma: 200, 2, 0.1\n",
      "0.19304025795280982, 0.204898222918268, 0.2032627116222021\n",
      "Experiment  387\n",
      "Inputs N, d, sigma: 200, 2, 1\n",
      "0.19472754949218068, 1.3831036177469855, 1.1134040203369666\n",
      "Experiment  388\n",
      "Inputs N, d, sigma: 200, 3, 0.01\n",
      "0.07582768668606431, 0.07786526902218978, 0.07668335957171303\n",
      "Experiment  389\n",
      "Inputs N, d, sigma: 200, 3, 0.1\n",
      "0.07925220412221183, 0.10823866135220239, 0.07954397062792073\n",
      "Experiment  390\n",
      "Inputs N, d, sigma: 200, 3, 1\n",
      "0.075818709968569, 2.5671152894804807, 0.08009708821711792\n",
      "Experiment  391\n",
      "Inputs N, d, sigma: 200, 4, 0.01\n",
      "0.0709967138848652, 0.07735757727029159, 0.07415668173376853\n",
      "Experiment  392\n",
      "Inputs N, d, sigma: 200, 4, 0.1\n",
      "0.07461883301481011, 0.0897846795282058, 0.08140995422581077\n",
      "Experiment  393\n",
      "Inputs N, d, sigma: 200, 4, 1\n",
      "0.07391372290782669, 2.3345176723120074, 0.09853488927741978\n",
      "Experiment  394\n",
      "Inputs N, d, sigma: 200, 5, 0.01\n",
      "0.092398783232166, 0.0934507514924344, 0.09389636512160647\n",
      "Experiment  395\n",
      "Inputs N, d, sigma: 200, 5, 0.1\n",
      "0.08870244211646489, 0.11806134141600591, 0.09396973377683875\n",
      "Experiment  396\n",
      "Inputs N, d, sigma: 200, 5, 1\n",
      "0.09087674685417904, 3.0833034498643266, 0.6163314951729502\n",
      "Experiment  397\n",
      "Inputs N, d, sigma: 200, 6, 0.01\n",
      "0.09769576822525537, 0.10419935747075744, 0.09926942320942951\n",
      "Experiment  398\n",
      "Inputs N, d, sigma: 200, 6, 0.1\n",
      "0.10145581229389589, 0.1128728246686403, 0.10956293450222059\n",
      "Experiment  399\n",
      "Inputs N, d, sigma: 200, 6, 1\n",
      "0.09844284891678937, 2.3165639665337725, 3.1785815238392026\n",
      "Experiment  400\n",
      "Inputs N, d, sigma: 200, 7, 0.01\n",
      "0.10168538406278615, 0.1081327161271414, 0.10106628492962776\n",
      "Experiment  401\n",
      "Inputs N, d, sigma: 200, 7, 0.1\n",
      "0.10043045490561309, 0.1309885678615038, 0.10267301618662779\n",
      "Experiment  402\n",
      "Inputs N, d, sigma: 200, 7, 1\n",
      "0.10007993584785443, 3.9689754765654386, 0.10783994082329905\n",
      "Experiment  403\n",
      "Inputs N, d, sigma: 200, 8, 0.01\n",
      "0.09391539930579608, 0.09740179604460342, 0.09390269830348216\n",
      "Experiment  404\n",
      "Inputs N, d, sigma: 200, 8, 0.1\n",
      "0.09502892157223874, 0.13509952066850806, 0.10110255014901129\n",
      "Experiment  405\n",
      "Inputs N, d, sigma: 200, 8, 1\n",
      "0.09419114684577477, 1.8298786754589358, 2.650001783953992\n",
      "Experiment  406\n",
      "Inputs N, d, sigma: 200, 9, 0.01\n",
      "0.0862864371999021, 0.09239250069193658, 0.09109381718145954\n",
      "Experiment  407\n",
      "Inputs N, d, sigma: 200, 9, 0.1\n",
      "0.08708246564686681, 0.10945011412592762, 0.10987051342324636\n",
      "Experiment  408\n",
      "Inputs N, d, sigma: 200, 9, 1\n",
      "0.0873471780991733, 2.8135500135904783, 3.887326208624004\n",
      "Experiment  409\n",
      "Inputs N, d, sigma: 200, 10, 0.01\n",
      "0.07720052350654542, 0.08135883256134023, 0.0792242023365698\n",
      "Experiment  410\n",
      "Inputs N, d, sigma: 200, 10, 0.1\n",
      "0.07852812105823519, 0.10098712735358457, 0.0807104891254221\n",
      "Experiment  411\n",
      "Inputs N, d, sigma: 200, 10, 1\n",
      "0.07878049620507967, 2.2014551655178405, 0.3895511814960118\n",
      "Experiment  412\n",
      "Inputs N, d, sigma: 200, 11, 0.01\n",
      "0.0692669566036385, 0.0720205473820393, 0.06914348132494838\n",
      "Experiment  413\n",
      "Inputs N, d, sigma: 200, 11, 0.1\n",
      "0.06921108312956528, 0.0919978412223174, 0.0736236696679439\n",
      "Experiment  414\n",
      "Inputs N, d, sigma: 200, 11, 1\n",
      "0.06940721059477283, 1.1935818961987281, 0.0880720553921883\n",
      "Experiment  415\n",
      "Inputs N, d, sigma: 200, 12, 0.01\n",
      "0.06147593915353389, 0.06327027552084322, 0.06221288134684671\n",
      "Experiment  416\n",
      "Inputs N, d, sigma: 200, 12, 0.1\n",
      "0.06106589275458576, 0.08389275943782096, 0.06761284952737374\n",
      "Experiment  417\n",
      "Inputs N, d, sigma: 200, 12, 1\n",
      "0.06306833086549374, 3.4851306938362945, 0.94480477939729\n",
      "Experiment  418\n",
      "Inputs N, d, sigma: 200, 13, 0.01\n",
      "0.05525194764586083, 0.057637303341181355, 0.05564290092976759\n",
      "Experiment  419\n",
      "Inputs N, d, sigma: 200, 13, 0.1\n",
      "0.05498074564070423, 0.07566145272945117, 0.057194058959686045\n",
      "Experiment  420\n",
      "Inputs N, d, sigma: 200, 13, 1\n",
      "0.05648793354750933, 1.8497623371446443, 2.048622549243268\n",
      "Experiment  421\n",
      "Inputs N, d, sigma: 200, 14, 0.01\n",
      "0.053210315198177836, 0.05540004028513791, 0.0533804830200003\n",
      "Experiment  422\n",
      "Inputs N, d, sigma: 200, 14, 0.1\n",
      "0.053352955418928996, 0.07064851932000386, 0.05548889769187097\n",
      "Experiment  423\n",
      "Inputs N, d, sigma: 200, 14, 1\n",
      "0.05308234120100579, 2.049247477788091, 0.059096977577513886\n",
      "Experiment  424\n",
      "Inputs N, d, sigma: 200, 15, 0.01\n",
      "0.050498094586125676, 0.05161504491778911, 0.050009535142194673\n",
      "Experiment  425\n",
      "Inputs N, d, sigma: 200, 15, 0.1\n",
      "0.04859760557808184, 0.07044530454879257, 0.05430094687306968\n",
      "Experiment  426\n",
      "Inputs N, d, sigma: 200, 15, 1\n",
      "0.05053152825443431, 2.7662815802276044, 6.1639864820204515\n",
      "Experiment  427\n",
      "Inputs N, d, sigma: 200, 16, 0.01\n",
      "0.0475036985206463, 0.05004932067913144, 0.04847031394761974\n",
      "Experiment  428\n",
      "Inputs N, d, sigma: 200, 16, 0.1\n",
      "0.049367159244527746, 0.06106839385822534, 0.05024430038337122\n",
      "Experiment  429\n",
      "Inputs N, d, sigma: 200, 16, 1\n",
      "0.0476631150875105, 1.4009676113569585, 0.20441943998031123\n",
      "Experiment  430\n",
      "Inputs N, d, sigma: 200, 17, 0.01\n",
      "0.04704709858259175, 0.048238713605880335, 0.04721880518274281\n",
      "Experiment  431\n",
      "Inputs N, d, sigma: 200, 17, 0.1\n",
      "0.048643282115184316, 0.07174260305391364, 0.053776294894971835\n",
      "Experiment  432\n",
      "Inputs N, d, sigma: 200, 17, 1\n",
      "0.047550112196909196, 3.1415849139031633, 0.8305978428608358\n",
      "Experiment  433\n",
      "Inputs N, d, sigma: 200, 18, 0.01\n",
      "0.049038979685987714, 0.04899756547247997, 0.051042182013594735\n",
      "Experiment  434\n",
      "Inputs N, d, sigma: 200, 18, 0.1\n",
      "0.04884217504890665, 0.07957672961478676, 0.04876839167142809\n",
      "Experiment  435\n",
      "Inputs N, d, sigma: 200, 18, 1\n",
      "0.048398095745971044, 1.107712819669615, 1.7788380404081405\n",
      "Experiment  436\n",
      "Inputs N, d, sigma: 200, 19, 0.01\n",
      "0.04988494255217774, 0.051129005575813055, 0.052349295345363124\n",
      "Experiment  437\n",
      "Inputs N, d, sigma: 200, 19, 0.1\n",
      "0.04933075807961067, 0.09047246270052593, 0.049397457135486475\n",
      "Experiment  438\n",
      "Inputs N, d, sigma: 200, 19, 1\n",
      "0.04998737997948519, 1.9861001479399516, 0.5479710522858973\n",
      "Experiment  439\n",
      "Inputs N, d, sigma: 200, 20, 0.01\n",
      "0.04960149375288674, 0.051492272468136646, 0.050833747678210174\n",
      "Experiment  440\n",
      "Inputs N, d, sigma: 200, 20, 0.1\n",
      "0.04934395602400091, 0.07164067258681146, 0.05857044619120416\n",
      "Experiment  441\n",
      "Inputs N, d, sigma: 200, 20, 1\n",
      "0.05023273760949234, 2.2185790425656178, 1.3464807808965191\n"
     ]
    }
   ],
   "source": [
    "# testing\n",
    "# bigN = [50]\n",
    "# deg = [4]\n",
    "# sigmas = [0.1]\n",
    "\n",
    "experiments = []\n",
    "\n",
    "cntCombinations = 0\n",
    "print(\"Number combinations: \", numCombinations)\n",
    "\n",
    "for n in bigN:\n",
    "    for d in deg:\n",
    "        for sigma in sigmas:\n",
    "            cntCombinations+=1\n",
    "            Ein_avg, Eout_avg, Ebias = experiment(n, d, sigma, lambd)\n",
    "            \n",
    "            print(\"Experiment \", cntCombinations)\n",
    "            print(\"Inputs N, d, sigma: %s, %s, %s\" % (n, d, sigma))\n",
    "            print(\"%s, %s, %s\" % (Ein_avg, Eout_avg, Ebias))\n",
    "            experiments.append([n, d, sigma, Ein_avg, Eout_avg, Ebias])\n",
    "\n",
    "# save experiment\n",
    "with open(\".\\experiments\\experiments_8\", 'w', encoding=\"utf-8\") as fout:\n",
    "    pprint(experiments, fout)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_report_graph(x, y_data):\n",
    "    for entry in data:\n",
    "        y, label = y_data\n",
    "        plt.plot(y, label=label)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot_report_graph' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-164-834d3111e7ed>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[0my_Ebias\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mn_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbigN\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m \u001b[0mplot_report_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbigN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my_Ein\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Ein\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0my_Eout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Eout\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0my_Ebias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Ebias\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;31m# plt.plot(bigN, y_Ein)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;31m# plt.plot(bigN, y_Eout)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plot_report_graph' is not defined"
     ]
    }
   ],
   "source": [
    "# do fun stuff with experiment\n",
    "with open(\".\\experiments\\experiments_reg_6\", \"r\", encoding='utf-8') as f:\n",
    "    experiments = eval(f.read())\n",
    "    \n",
    "n_dict, d_dict, sigma_dict = dict(), dict(), dict()\n",
    "for exp in experiments:\n",
    "    n, d, s = exp[0], exp[1], exp[2]\n",
    "    \n",
    "    n_dict[n] = n_dict.get(n, np.array([0, 0, 0])) + np.array(exp[3:6])\n",
    "    d_dict[d] = d_dict.get(d, np.array([0, 0, 0])) + np.array(exp[3:6])\n",
    "    sigma_dict[s] = sigma_dict.get(s, np.array([0, 0, 0])) + np.array(exp[3:6])\n",
    "\n",
    "# avg (this actually isn't needed if I am normalizing from range 0 to 1)\n",
    "n_dict = {k: x/(numCombinations/len(n_dict)) for k, x in n_dict.items()}\n",
    "d_dict = {k: x/(numCombinations/len(d_dict)) for k, x in d_dict.items()}\n",
    "sigma_dict = {k: x/(numCombinations/len(sigma_dict)) for k, x in sigma_dict.items()}\n",
    "\n",
    "# pprint(n_dict)\n",
    "# pprint(d_dict)\n",
    "# pprint(sigma_dict)\n",
    "\n",
    "# plot n vs Ein_avg, Eout_avg, Ebias\n",
    "y_Ein = [n_dict[n][0] for n in bigN]\n",
    "y_Eout = [n_dict[n][1] for n in bigN]\n",
    "y_Ebias = [n_dict[n][2] for n in bigN]\n",
    "\n",
    "plot_report_graph(bigN, [[y_Ein, \"Ein\"], [y_Eout, \"Eout\"], [y_Ebias, \"Ebias\"]])\n",
    "# plt.plot(bigN, y_Ein)\n",
    "# plt.plot(bigN, y_Eout)\n",
    "# plt.plot(bigN, y_Ebias)\n",
    "# plt.show()\n",
    "\n",
    "# plot deg vs Ein_avg, Eout_avg, Ebias\n",
    "y_Ein = [d_dict[n][0] for n in deg]\n",
    "y_Eout = [d_dict[n][1] for n in deg]\n",
    "y_Ebias = [d_dict[n][2] for n in deg]\n",
    "\n",
    "plt.plot(deg, y_Ein)\n",
    "plt.plot(deg, y_Eout)\n",
    "plt.plot(deg, y_Ebias)\n",
    "plt.show()\n",
    "\n",
    "# plot sigma vs Ein_avg, Eout_avg, Ebias\n",
    "y_Ein = [sigma_dict[n][0] for n in sigmas]\n",
    "y_Eout = [sigma_dict[n][1] for n in sigmas]\n",
    "y_Ebias = [sigma_dict[n][2] for n in sigmas]\n",
    "\n",
    "plt.plot(sigmas, y_Ein)\n",
    "plt.plot(sigmas, y_Eout)\n",
    "plt.plot(sigmas, y_Ebias)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
